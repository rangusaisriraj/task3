{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":540888,"status":"ok","timestamp":1661776240566,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"cP7V-osQp-GM","outputId":"385887fa-6dda-42a5-ddf0-43175529b274"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1661776240569,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"1tZaJebCbV_O","outputId":"7fcf70f7-9a4a-46b2-d972-b6a4905a6760"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Task\n"]}],"source":["cd /content/drive/MyDrive/Task"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"__9QUXhnEEe6","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1661776502724,"user_tz":-330,"elapsed":214471,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"}},"outputId":"e54dd4fe-2632-4e83-efcd-7f18e1565368"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting opencv-python==4.5.5.64\n","  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n","\u001b[K     |████████████████████████████████| 60.5 MB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.5.64) (1.21.6)\n","Installing collected packages: opencv-python\n","  Attempting uninstall: opencv-python\n","    Found existing installation: opencv-python 4.6.0.66\n","    Uninstalling opencv-python-4.6.0.66:\n","      Successfully uninstalled opencv-python-4.6.0.66\n","Successfully installed opencv-python-4.5.5.64\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cv2"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Found existing installation: imgaug 0.4.0\n","Uninstalling imgaug-0.4.0:\n","  Successfully uninstalled imgaug-0.4.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting imgaug==0.2.5\n","  Downloading imgaug-0.2.5.tar.gz (562 kB)\n","\u001b[K     |████████████████████████████████| 562 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.7.3)\n","Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (0.18.3)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.21.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.15.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2021.11.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.6.3)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.9.0)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (1.3.0)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (3.2.2)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (7.1.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (4.1.1)\n","Building wheels for collected packages: imgaug\n","  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imgaug: filename=imgaug-0.2.5-py3-none-any.whl size=561438 sha256=d41e3feb686032f4b2df02593271afe0cb2f47e8836b29fac70e016361f24519\n","  Stored in directory: /root/.cache/pip/wheels/60/dd/38/d1dc2cad2b6a66dc0249261004990bccb0f27985c74ba26e49\n","Successfully built imgaug\n","Installing collected packages: imgaug\n","Successfully installed imgaug-0.2.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting webcolors\n","  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n","Collecting xlsxwriter\n","  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n","\u001b[K     |████████████████████████████████| 149 kB 4.1 MB/s \n","\u001b[?25hCollecting youtube-dl\n","  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 31.8 MB/s \n","\u001b[?25hCollecting SpeechRecognition\n","  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n","\u001b[K     |████████████████████████████████| 32.8 MB 398 kB/s \n","\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n","Collecting ffmpeg\n","  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n","Collecting spleeter\n","  Downloading spleeter-2.3.1-py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 7.0 MB/s \n","\u001b[?25hCollecting fer\n","  Downloading fer-22.4.0-py3-none-any.whl (812 kB)\n","\u001b[K     |████████████████████████████████| 812 kB 54.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.64.0)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy) (1.21.6)\n","Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.9.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n","Collecting ffmpeg-python==0.2.0\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: pandas<2.0.0,>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from spleeter) (1.3.5)\n","Collecting importlib-metadata<4.0.0,>=3.0.0\n","  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n","Collecting numpy\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","\u001b[K     |████████████████████████████████| 14.8 MB 41.6 MB/s \n","\u001b[?25hCollecting librosa==0.8.0\n","  Downloading librosa-0.8.0.tar.gz (183 kB)\n","\u001b[K     |████████████████████████████████| 183 kB 75.2 MB/s \n","\u001b[?25hCollecting tensorflow==2.5.0\n","  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n","\u001b[K     |████████████████████████████████| 454.3 MB 14 kB/s \n","\u001b[?25hCollecting llvmlite<0.37.0,>=0.36.0\n","  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n","\u001b[K     |████████████████████████████████| 25.3 MB 1.4 MB/s \n","\u001b[?25hCollecting typer<0.4.0,>=0.3.2\n","  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n","Collecting httpx[http2]<0.20.0,>=0.19.0\n","  Downloading httpx-0.19.0-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.0 MB/s \n","\u001b[?25hCollecting norbert==0.2.1\n","  Downloading norbert-0.2.1-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: protobuf<=3.19.4 in /usr/local/lib/python3.7/dist-packages (from spleeter) (3.17.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python==0.2.0->spleeter) (0.16.0)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (3.0.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.7.3)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.0.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.1.0)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (0.4.0)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (0.56.0)\n","Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (0.10.3.post1)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.6.0)\n","Collecting typing-extensions~=3.7.4\n","  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.15.0)\n","Collecting grpcio~=1.34.0\n","  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 47.0 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (2.8.0)\n","Collecting flatbuffers~=1.12.0\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.1.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (0.37.1)\n","Collecting gast==0.4.0\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.1.2)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.6.3)\n","Collecting keras-nightly~=2.5.0.dev\n","  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 58.1 MB/s \n","\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n","  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 49.7 MB/s \n","\u001b[?25hCollecting absl-py~=0.10\n","  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 62.3 MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (3.3.0)\n","Collecting wrapt~=1.12.1\n","  Downloading wrapt-1.12.1.tar.gz (27 kB)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (0.2.0)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (3.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.0->spleeter) (1.5.2)\n","Collecting rfc3986[idna2008]<2,>=1.3\n","  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (2022.6.15)\n","Collecting httpcore<0.14.0,>=0.13.3\n","  Downloading httpcore-0.13.7-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 4.5 MB/s \n","\u001b[?25hCollecting sniffio\n","  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (2.1.0)\n","Collecting h2<5,>=3\n","  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 4.0 MB/s \n","\u001b[?25hCollecting hyperframe<7,>=6.0\n","  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n","Collecting hpack<5,>=4.0\n","  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n","Collecting h11<0.13,>=0.11\n","  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 3.2 MB/s \n","\u001b[?25hCollecting anyio==3.*\n","  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 10.1 MB/s \n","\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.0.0->spleeter) (3.8.1)\n","Collecting numba>=0.43.0\n","  Downloading numba-0.55.2-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 42.1 MB/s \n","\u001b[?25h  Downloading numba-0.55.1-1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 54.9 MB/s \n","\u001b[?25h  Downloading numba-0.55.0-1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 51.7 MB/s \n","\u001b[?25h  Downloading numba-0.54.1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 42.0 MB/s \n","\u001b[?25h  Downloading numba-0.54.0-2-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 15.8 MB/s \n","\u001b[?25h  Downloading numba-0.53.1-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 11.4 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.0->spleeter) (57.4.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.1.2->spleeter) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.1.2->spleeter) (2022.2.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->spleeter) (21.3)\n","Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->spleeter) (1.4.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->spleeter) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->pooch>=1.0->librosa==0.8.0->spleeter) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->spleeter) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->spleeter) (3.0.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0->spleeter) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa==0.8.0->spleeter) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.8.0->spleeter) (2.21)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (3.4.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.4.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.3.1)\n","Collecting markdown>=2.6.8\n","  Downloading Markdown-3.4-py3-none-any.whl (93 kB)\n","\u001b[K     |████████████████████████████████| 93 kB 1.8 MB/s \n","\u001b[?25h  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 7.6 MB/s \n","\u001b[?25h  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 7.8 MB/s \n","\u001b[?25h  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (3.2.0)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.2->spleeter) (7.1.2)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from fer) (4.6.0.66)\n","Collecting mtcnn>=0.1.1\n","  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 44.5 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fer) (3.2.2)\n","Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from fer) (2.8.0)\n","Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn>=0.1.1->fer) (4.5.5.64)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (1.4.4)\n","Building wheels for collected packages: ffmpeg, librosa, wrapt\n","  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6084 sha256=f4808af6d474b43dbfceb340786ddf3642016f7d7dda4b57895fc3397375585a\n","  Stored in directory: /root/.cache/pip/wheels/64/80/6e/caa3e16deb0267c3cbfd36862058a724144e19fdb9eb03af0f\n","  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201396 sha256=a1702bd34831df695fddf1d1d4b2552e413399fe41daab077bb9392c049754c8\n","  Stored in directory: /root/.cache/pip/wheels/de/1e/aa/d91797ae7e1ce11853ee100bee9d1781ae9d750e7458c95afb\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68713 sha256=e035e10238d5007d5adf45cb0d46dad1b51141c880db97cfe37d98b77cf4546b\n","  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n","Successfully built ffmpeg librosa wrapt\n","Installing collected packages: typing-extensions, sniffio, rfc3986, numpy, llvmlite, importlib-metadata, h11, anyio, numba, markdown, hyperframe, httpcore, hpack, grpcio, absl-py, wrapt, tensorflow-estimator, keras-nightly, httpx, h2, gast, flatbuffers, typer, tensorflow, norbert, mtcnn, librosa, ffmpeg-python, youtube-dl, xlsxwriter, webcolors, spleeter, SpeechRecognition, ffmpeg, fer\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.1.1\n","    Uninstalling typing-extensions-4.1.1:\n","      Successfully uninstalled typing-extensions-4.1.1\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.39.0\n","    Uninstalling llvmlite-0.39.0:\n","      Successfully uninstalled llvmlite-0.39.0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.12.0\n","    Uninstalling importlib-metadata-4.12.0:\n","      Successfully uninstalled importlib-metadata-4.12.0\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.56.0\n","    Uninstalling numba-0.56.0:\n","      Successfully uninstalled numba-0.56.0\n","  Attempting uninstall: markdown\n","    Found existing installation: Markdown 3.4.1\n","    Uninstalling Markdown-3.4.1:\n","      Successfully uninstalled Markdown-3.4.1\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.47.0\n","    Uninstalling grpcio-1.47.0:\n","      Successfully uninstalled grpcio-1.47.0\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.2.0\n","    Uninstalling absl-py-1.2.0:\n","      Successfully uninstalled absl-py-1.2.0\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.14.1\n","    Uninstalling wrapt-1.14.1:\n","      Successfully uninstalled wrapt-1.14.1\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 2.0\n","    Uninstalling flatbuffers-2.0:\n","      Successfully uninstalled flatbuffers-2.0\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.4.2\n","    Uninstalling typer-0.4.2:\n","      Successfully uninstalled typer-0.4.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n","    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n","      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n","  Attempting uninstall: librosa\n","    Found existing installation: librosa 0.8.1\n","    Uninstalling librosa-0.8.1:\n","      Successfully uninstalled librosa-0.8.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n","gym 0.25.1 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n","cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n","Successfully installed SpeechRecognition-3.8.1 absl-py-0.15.0 anyio-3.6.1 fer-22.4.0 ffmpeg-1.4 ffmpeg-python-0.2.0 flatbuffers-1.12 gast-0.4.0 grpcio-1.34.1 h11-0.12.0 h2-4.1.0 hpack-4.0.0 httpcore-0.13.7 httpx-0.19.0 hyperframe-6.0.1 importlib-metadata-3.10.1 keras-nightly-2.5.0.dev2021032900 librosa-0.8.0 llvmlite-0.36.0 markdown-3.3.4 mtcnn-0.1.1 norbert-0.2.1 numba-0.53.1 numpy-1.19.5 rfc3986-1.5.0 sniffio-1.2.0 spleeter-2.3.1 tensorflow-2.5.0 tensorflow-estimator-2.5.0 typer-0.3.2 typing-extensions-3.7.4.3 webcolors-1.12 wrapt-1.12.1 xlsxwriter-3.0.3 youtube-dl-2021.12.17\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","typing_extensions"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["deb https://ngrok-agent.s3.amazonaws.com buster main\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [91.1 kB]\n","Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n","Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [912 kB]\n","Get:8 https://ngrok-agent.s3.amazonaws.com buster InRelease [20.3 kB]\n","Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Hit:11 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:13 https://ngrok-agent.s3.amazonaws.com buster/main amd64 Packages [1,423 B]\n","Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,938 kB]\n","Hit:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,369 kB]\n","Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,534 kB]\n","Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,093 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,311 kB]\n","Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,073 kB]\n","Fetched 14.6 MB in 6s (2,393 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","37 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","The following NEW packages will be installed:\n","  ngrok\n","0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n","Need to get 6,630 kB of archives.\n","After this operation, 0 B of additional disk space will be used.\n","Get:1 https://ngrok-agent.s3.amazonaws.com buster/main amd64 ngrok amd64 3.0.7 [6,630 kB]\n","Fetched 6,630 kB in 2s (3,697 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package ngrok.\n","(Reading database ... 155676 files and directories currently installed.)\n","Preparing to unpack .../archives/ngrok_3.0.7_amd64.deb ...\n","Unpacking ngrok (3.0.7) ...\n","Setting up ngrok (3.0.7) ...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (1.1.4)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask) (1.1.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask) (1.0.1)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask) (2.11.3)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask) (2.0.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: youtube_dl in /usr/local/lib/python3.7/dist-packages (2021.12.17)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting flask_ngrok\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyngrok==4.1.1\n","  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (0.16.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (6.0)\n","Building wheels for collected packages: pyngrok\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15983 sha256=8c5ce29701809d6fcdc469bffd8604e8697de6f0890cd81bf66868e1a84fb180\n","  Stored in directory: /root/.cache/pip/wheels/b1/d9/12/045a042fee3127dc40ba6f5df2798aa2df38c414bf533ca765\n","Successfully built pyngrok\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-4.1.1\n","Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.8.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from wordcloud) (3.2.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from wordcloud) (1.19.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud) (3.7.4.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytrends\n","  Downloading pytrends-4.8.0.tar.gz (19 kB)\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.7/dist-packages (from pytrends) (2.23.0)\n","Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.7/dist-packages (from pytrends) (1.3.5)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pytrends) (4.9.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (2022.2.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25->pytrends) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0->pytrends) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0->pytrends) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0->pytrends) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0->pytrends) (1.24.3)\n","Building wheels for collected packages: pytrends\n","  Building wheel for pytrends (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytrends: filename=pytrends-4.8.0-py3-none-any.whl size=16126 sha256=801fc0d886ee893f13a0710dc401a598ea2e8755caab7768adddd0b47eb13dcf\n","  Stored in directory: /root/.cache/pip/wheels/07/6f/5c/8174f98dec1bfbc7d5da4092854afcbcff4b26c3d9b66b5183\n","Successfully built pytrends\n","Installing collected packages: pytrends\n","Successfully installed pytrends-4.8.0\n","Found existing installation: ffmpeg 1.4\n","Uninstalling ffmpeg-1.4:\n","  Successfully uninstalled ffmpeg-1.4\n","Found existing installation: ffmpeg-python 0.2.0\n","Uninstalling ffmpeg-python-0.2.0:\n","  Successfully uninstalled ffmpeg-python-0.2.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.7/dist-packages (3.8.1)\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n","Requirement already satisfied: spleeter in /usr/local/lib/python3.7/dist-packages (2.3.1)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy) (1.19.5)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.64.0)\n","Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.9.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n","Requirement already satisfied: httpx[http2]<0.20.0,>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from spleeter) (0.19.0)\n","Requirement already satisfied: typer<0.4.0,>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from spleeter) (0.3.2)\n","Requirement already satisfied: importlib-metadata<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spleeter) (3.10.1)\n","Requirement already satisfied: tensorflow==2.5.0 in /usr/local/lib/python3.7/dist-packages (from spleeter) (2.5.0)\n","Requirement already satisfied: llvmlite<0.37.0,>=0.36.0 in /usr/local/lib/python3.7/dist-packages (from spleeter) (0.36.0)\n","Collecting ffmpeg-python==0.2.0\n","  Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: protobuf<=3.19.4 in /usr/local/lib/python3.7/dist-packages (from spleeter) (3.17.3)\n","Requirement already satisfied: pandas<2.0.0,>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from spleeter) (1.3.5)\n","Requirement already satisfied: norbert==0.2.1 in /usr/local/lib/python3.7/dist-packages (from spleeter) (0.2.1)\n","Requirement already satisfied: librosa==0.8.0 in /usr/local/lib/python3.7/dist-packages (from spleeter) (0.8.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python==0.2.0->spleeter) (0.16.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.7.3)\n","Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (0.10.3.post1)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (0.4.0)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.6.0)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (0.53.1)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (3.0.0)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.0.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.1.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.12.1)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (0.4.0)\n","Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (2.5.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (3.3.0)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (3.1.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.6.3)\n","Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (2.5.0.dev2021032900)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.15.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (0.15.0)\n","Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (2.8.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.1.0)\n","Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.34.1)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (0.37.1)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.12)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (0.2.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.1.2)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (3.7.4.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.0->spleeter) (1.5.2)\n","Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.5.0)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (2.1.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (2022.6.15)\n","Requirement already satisfied: httpcore<0.14.0,>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (0.13.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.2.0)\n","Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (4.1.0)\n","Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.7/dist-packages (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (4.0.0)\n","Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.7/dist-packages (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (6.0.1)\n","Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.6.1)\n","Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.7/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (0.12.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.0.0->spleeter) (3.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.0->spleeter) (57.4.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.1.2->spleeter) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.1.2->spleeter) (2022.2.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->spleeter) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->spleeter) (21.3)\n","Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->spleeter) (1.4.4)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->pooch>=1.0->librosa==0.8.0->spleeter) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->spleeter) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->spleeter) (1.24.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0->spleeter) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa==0.8.0->spleeter) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.8.0->spleeter) (2.21)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (3.3.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.3.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (3.2.0)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.2->spleeter) (7.1.2)\n","Installing collected packages: ffmpeg-python\n","Successfully installed ffmpeg-python-0.2.0\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"]}],"source":["def requirements():\n","  !pip install opencv-python==4.5.5.64\n","  !pip uninstall imgaug --y\n","  !pip install imgaug==0.2.5\n","  !pip install webcolors  xlsxwriter youtube-dl SpeechRecognition moviepy ffmpeg spleeter fer\n","  #Extras\n","  !curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list &&sudo apt update &&sudo apt install ngrok \n","  !pip install flask\n","  !pip install youtube_dl\n","  !pip install flask_ngrok\n","  !pip install pyngrok==4.1.1\n","  !ngrok authtoken 27hMUYstXU9FbCK7ejYIWnDwu3g_3Bt3PL1LoHseoRkPySH5A\n","  !pip install pydub\n","\n","\n","  #audio module depedencies are present already\n","\n","  !pip install wordcloud\n","\n","  #Trends module depedencies\n","  !pip install pytrends\n","\n","  !pip3 uninstall FFmpeg ffmpeg-python --y\n","\n","  !pip install SpeechRecognition moviepy spleeter pydub\n","  #!pip3 uninstall FFmpeg ffmpeg-python\n","  !apt install ffmpeg\n","\n","requirements()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":946,"status":"ok","timestamp":1661776241491,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"RSYCHryWeyr2","outputId":"544810ed-df28-402c-99ce-070298f28368"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Task/object_detection_model\n"]}],"source":["cd /content/drive/MyDrive/Task/object_detection_model"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12829,"status":"ok","timestamp":1661776532403,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"om9PXWe6_lrN","outputId":"3d0643d5-f9e2-4a8b-d783-428f5c890b4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'yolov5' already exists and is not an empty directory.\n","/content/drive/MyDrive/Task/yolov5\n","\u001b[K     |████████████████████████████████| 1.6 MB 4.3 MB/s \n","\u001b[?25h"]}],"source":["!git clone https://github.com/ultralytics/yolov5  # clone\n","%cd yolov5\n","%pip install -qr requirements.txt  # install\n","import torch\n","import utils"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1661776532405,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"E4iWaaqQffP-","outputId":"b57de4b8-660c-4645-9249-43164e95213e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Task\n"]}],"source":["cd /content/drive/MyDrive/Task"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":575,"status":"ok","timestamp":1661776604939,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"vkRYO378I7tK"},"outputs":[],"source":["import urllib.request\n","import re\n","import cv2\n","from PIL import Image\n","import os\n","import glob\n","import pandas as pd\n","import youtube_dl\n","from glob import glob\n","import numpy as np\n","import torch\n","import math\n","import webcolors\n","from fer import Video, FER\n","from scipy.spatial import KDTree\n","from sklearn.cluster import KMeans\n","from collections import Counter\n","import urllib.request\n","import shutil\n","import time\n","import matplotlib\n","from google.colab.patches import cv2_imshow\n","import xlsxwriter\n","import xlwt\n","from xlwt.Workbook import *\n","from pandas import ExcelWriter\n","from IPython.display import HTML\n","from base64 import b64encode\n","from IPython.display import Audio\n","import speech_recognition as sr \n","#import moviepy.editor as mp\n","from pydub import AudioSegment\n","from pydub.silence import split_on_silence\n","from os import path\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud, STOPWORDS\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud, STOPWORDS\n","\n","#audio module depedencies are already present\n","import ffmpeg\n","\n","\n","#Trends                        \n","from pytrends.request import TrendReq\n","from google.colab import files\n","\n","\n","###extra\n","from flask import Flask,redirect,url_for,render_template,request\n","from flask_ngrok import run_with_ngrok\n","from glob import glob\n","from time import sleep\n","from threading import Thread"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"mwBloFPq-RLO","executionInfo":{"status":"ok","timestamp":1661776618522,"user_tz":-330,"elapsed":1805,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"}}},"outputs":[],"source":["def ana():\n","\n","      \n","      #//1\n","      #color names\n","      sleep(1)\n","      hexcodes = []\n","      colornames = []\n","\n","      for cname, hex in matplotlib.colors.cnames.items():\n","          hexcodes.append(hex)\n","          colornames.append(cname)\n","          #print(hex,cname)\n","\n","      zipbObj = zip(hexcodes, colornames)\n","      new_hex_colors = dict(zipbObj)\n","\n","      def RGB2HEX(color):\n","          return \"#{:02x}{:02x}{:02x}\".format(int(color[0]), int(color[1]), int(color[2]))\n","      #//2\n","      def closer_color(image):\n","          hexnames = new_hex_colors\n","          names = []\n","          positions = []\n","          \n","          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","          dst = cv2.fastNlMeansDenoisingColored(image,None,10,10,7,21)\n","          modified_image = cv2.resize(dst, (600, 400), interpolation = cv2.INTER_AREA)\n","          \n","          input_image = image.reshape(image.shape[0]*image.shape[1], 3)\n","          clf = KMeans(n_clusters = 1)\n","          labels = clf.fit_predict(input_image)\n","          counts = Counter(labels)\n","\n","          center_colors = clf.cluster_centers_\n","          \n","          ordered_colors = [center_colors[i] for i in counts.keys()]\n","          hex_colors = [RGB2HEX(ordered_colors[i]) for i in counts.keys()]\n","          rgb_colors = [ordered_colors[i] for i in counts.keys()]\n","          \n","          for i in hexnames:\n","              names.append(hexnames[i])\n","              positions.append(webcolors.hex_to_rgb(i))\n","              \n","          spacedb = KDTree(positions)\n","\n","          x = rgb_colors\n","          \n","          x[0] = [int(i) for i in x[0]]\n","          dist, index = spacedb.query(x[0])\n","          \n","          return names[index]\n","      #//3\n","      #loading object detection model\n","      \n","      \n","      \n","      def object_detection():\n","        model = torch.hub.load(\"/content/drive/MyDrive/Task/object_detection_model/yolov5\", 'yolov5s', source = 'local') \n","        return model\n","      \n","      #//4\n","      object_model = object_detection()\n","\n","      #//5\n","      def highlightFace(net, frame, conf_threshold=0.7):\n","          frameOpencvDnn=frame.copy()\n","          frameHeight=frameOpencvDnn.shape[0]\n","          frameWidth=frameOpencvDnn.shape[1]\n","          blob=cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n","\n","          net.setInput(blob)\n","          detections=net.forward()\n","          faceBoxes=[]\n","          for i in range(detections.shape[2]):\n","              confidence=detections[0,0,i,2]\n","              if confidence>conf_threshold:\n","                  x1=int(detections[0,0,i,3]*frameWidth)\n","                  y1=int(detections[0,0,i,4]*frameHeight)\n","                  x2=int(detections[0,0,i,5]*frameWidth)\n","                  y2=int(detections[0,0,i,6]*frameHeight)\n","                  faceBoxes.append([x1,y1,x2,y2])\n","                  cv2.rectangle(frameOpencvDnn, (x1,y1), (x2,y2), (0,255,0), int(round(frameHeight/150)), 8)\n","          return frameOpencvDnn,faceBoxes\n","\n","      faceProto=\"gender_age_detection_model/opencv_face_detector.pbtxt\"\n","      faceModel=\"gender_age_detection_model/opencv_face_detector_uint8.pb\"\n","\n","      ageProto=\"gender_age_detection_model/age_deploy.prototxt\"\n","      ageModel=\"gender_age_detection_model/age_net.caffemodel\"\n","\n","      genderProto=\"gender_age_detection_model/gender_deploy.prototxt\"\n","      genderModel=\"gender_age_detection_model/gender_net.caffemodel\"\n","\n","      MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746)\n","      ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n","      genderList=['Male','Female']\n","\n","      faceNet=cv2.dnn.readNet(faceModel,faceProto)\n","      ageNet=cv2.dnn.readNet(ageModel,ageProto)\n","      genderNet=cv2.dnn.readNet(genderModel,genderProto)\n","\n","      padding=20\n","\n","\n","      def age_gender_detector(temp):\n","        obj_frame_no= []\n","        object_name = []\n","        color_name = []\n","        gender_name =[]\n","        age_group = []\n","        gender_frame_no = []\n","        fn = 0\n","        return_data1 = []\n","        return_data2 = []\n","        return_data3 = []\n","        for num in range(len(temp)):\n","          im = temp[num]\n","          frame = cv2.imread(im)\n","          print(f\"image number:{im}\")\n","          fn += 1\n","          \n","\n","          t=time.time()\n","          resultImg,faceBoxes=highlightFace(faceNet,frame)\n","          \n","          \n","          \n","          if not faceBoxes:\n","            gender_name.append(\"NaN\")\n","            age_group.append(\"NaN\")\n","            gender_frame_no.append(fn)\n","            print(\"No face detected\") \n","          \n","              \n","          for faceBox in faceBoxes:\n","              print(faceBox)\n","              face=frame[max(0,faceBox[1]-padding):\n","                        min(faceBox[3]+padding,frame.shape[0]-1),max(0,faceBox[0]-padding)\n","                        :min(faceBox[2]+padding, frame.shape[1]-1)]\n","              a = max(0,faceBox[1]-padding)\n","              b = min(faceBox[3]+padding,frame.shape[0]-1)\n","              c = max(0,faceBox[0]-padding)\n","              d = min(faceBox[2]+padding, frame.shape[1]-1)\n","              print(\"CHECKING THE FACE FRAME\", len(face), \n","                    \"\\n\", max(0,faceBox[1]-padding), \n","                    \"\\t\", min(faceBox[3]+padding,frame.shape[0]-1), \n","                    \"\\n\", max(0,faceBox[0]-padding), \n","                    \"\\t\", min(faceBox[2]+padding, frame.shape[1]-1))\n","              if(len(face) != 0) and (a != b and c != d): \n","                print(a,c, \"\\n\")\n","                print(b,d)\n","                if(a>b and c>d) or (a<b and c<d):\n","                  blob=cv2.dnn.blobFromImage(face, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False)\n","\n","              #running gender detection model\n","              genderNet.setInput(blob)\n","              genderPreds=genderNet.forward()\n","              gender=genderList[genderPreds[0].argmax()]\n","              #print(\"Gender Type\", type(gender))\n","              #running age detection model\n","              ageNet.setInput(blob)\n","              agePreds=ageNet.forward()\n","              age=ageList[agePreds[0].argmax()]\n","              gender_name.append(gender)\n","              age_group.append(age)\n","              gender_frame_no.append(fn)\n","              color_name.append(closer_color(frame))\n","              results = object_model(frame)\n","              objects = results.pandas().xyxy[0]\n","              for i in objects[\"name\"]:\n","                obj_frame_no.append(fn)\n","                object_name.append(i)\n","              label = \"{},{}\".format(gender, age)\n","              cv2.putText(resultImg, f'{gender}, {age}', (faceBox[0], faceBox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2, cv2.LINE_AA)\n","              #cv2.imshow(\"Age Gender Demo\", resultImg)\n","              #print(\"Gender\", gender_name)\n","              \n","          return_data1 = pd.DataFrame({'gender_frame':gender_frame_no,'gender_name': gender_name,'age_group': age_group})#[gender_frame_no, gender_name, age_group]\n","          return_data2 = pd.DataFrame({'object_name': object_name})\n","          return_data3 = pd.DataFrame({'color_name':color_name})\n","        # return resultImg\n","        #name = \"DataFrame.xlsx\"\n","        #return_data1.to_excel(name)\n","        return return_data1,return_data2,return_data3\n","\n","      #//6\n","      folders_path = \"/content/drive/MyDrive/Task/save/\"\n","      video_frames_dir = []\n","      vidframe_list1 =[]\n","      vidframe_list2 =[]\n","      vidframe_list3 =[]\n","      vidframe_list4 =[]\n","      vidframe_list5 = []\n","\n","      for root, subdirectories, files in os.walk(folders_path):\n","          for subdirectory in subdirectories:\n","              video_frames_dir.append(os.path.join(root, subdirectory))\n","\n","      #//7\n","      for x in os.listdir(video_frames_dir[0]):\n","          vidframe_list1.append(os.path.join(video_frames_dir[0],x)) \n","\n","      for x in os.listdir(video_frames_dir[1]):\n","          vidframe_list2.append(os.path.join(video_frames_dir[1],x))  \n","\n","      for x in os.listdir(video_frames_dir[2]):\n","          vidframe_list3.append(os.path.join(video_frames_dir[2],x)) \n","\n","      for x in os.listdir(video_frames_dir[3]):\n","         vidframe_list4.append(os.path.join(video_frames_dir[3],x))\n","\n","      for x in os.listdir(video_frames_dir[4]):\n","         vidframe_list5.append(os.path.join(video_frames_dir[4],x)) \n","\n","      #//8\n","      all_list = [vidframe_list1,vidframe_list2,vidframe_list3,vidframe_list4,vidframe_list5]#\n","      #//9\n","      for j in range(0, len(all_list)):\n","        temp = all_list[j]\n","        print(\"Folder Number: \", j+1)\n","        gender_details,object_details,color_details = age_gender_detector(temp)\n","        print(\"done\")\n","        excel_name = \"Folder_\" + str(j+1) + \".xlsx\"\n","        excelfile = pd.ExcelWriter(excel_name)\n","        gender_details.to_excel(excelfile, \"Gender\")\n","        object_details.to_excel(excelfile, \"Object\")\n","        color_details.to_excel(excelfile, \"Color\")\n","        excelfile.save()\n","        print(\"SAVED EXCEL\")\n","     \n","      \n","      print(\"Fin ana>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n","      global ana_status\n","      ana_status=ana_status+1\n","      return\n","\n","\n","def face():\n","      video_files = glob(r\"/content/drive/MyDrive/Task/*.mp4\")\n","      len(video_files)\n","\n","      vidf=video_files[1:]\n","      vidf.append(video_files[0])\n","\n","      # from mtcnn import MTCNN\n","      face_detector = FER(mtcnn=True)\n","      for vid in range(0,len(video_files)):\n","        temp1 = vidf[vid]\n","        input_video = Video(temp1)\n","        processing_data = input_video.analyze(face_detector, display=False)\n","        vid_df = input_video.to_pandas(processing_data)\n","        vid_df = input_video.get_first_face(vid_df)\n","        vid_df = input_video.get_emotions(vid_df)\n","        angry = sum(vid_df.angry)\n","        disgust = sum(vid_df.disgust)\n","        fear = sum(vid_df.fear)\n","        happy = sum(vid_df.happy)\n","        sad = sum(vid_df.sad)\n","        surprise = sum(vid_df.surprise)\n","        neutral = sum(vid_df.neutral)\n","        emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n","        emotions_values = [angry, disgust, fear, happy, sad, surprise, neutral]\n","        score_comparisons = pd.DataFrame(emotions, columns = ['Human Emotions'])\n","        score_comparisons['Emotion Value'] = [round(x,2) for x in emotions_values]\n","        score_comparisons.sort_values(by = ['Emotion Value'],inplace = True, ascending = False)\n","        print(score_comparisons)\n","        excel_name = \"/content/drive/MyDrive/Task/Emotions_Folder_\" + str(vid+1) + \".xlsx\"\n","        excelfile = pd.ExcelWriter(excel_name)\n","        score_comparisons.to_excel(excelfile, \"Emotions\")\n","        excelfile.save()\n","\n","      global ana_status\n","      ana_status=ana_status+1\n","      return\n","\n","\n","\n","\n","def create_audio():\n","    \n","        #for uploaded video\n","    clip1 = mp.VideoFileClip(r\"/content/drive/MyDrive/Task/video0.mp4\") \n","    \n","    clip1.audio.write_audiofile(r\"/content/drive/MyDrive/Task/A0.mp3\")\n","    #for video1\n","    clip1 = mp.VideoFileClip(r\"/content/drive/MyDrive/Task/video1.mp4\") \n","    \n","    clip1.audio.write_audiofile(r\"/content/drive/MyDrive/Task/A1.mp3\")\n","    #for video2\n","    clip1 = mp.VideoFileClip(r\"/content/drive/MyDrive/Task/video2.mp4\") \n","    \n","    clip1.audio.write_audiofile(r\"/content/drive/MyDrive/Task/A2.mp3\")\n","    #for video3\n","    clip1 = mp.VideoFileClip(r\"/content/drive/MyDrive/Task/video3.mp4\") \n","    \n","    clip1.audio.write_audiofile(r\"/content/drive/MyDrive/Task/A3.mp3\")\n","    #for video4\n","    clip1 = mp.VideoFileClip(r\"/content/drive/MyDrive/Task/video4.mp4\") \n","    \n","    clip1.audio.write_audiofile(r\"/content/drive/MyDrive/Task/A4.mp3\")\n","\n","    !spleeter separate -o /content/drive/MyDrive/Task/audioout/ /content/drive/MyDrive/Task/A0.mp3 #uploaded video\n","    !spleeter separate -o /content/drive/MyDrive/Task/audioout/ /content/drive/MyDrive/Task/A1.mp3 #for video1\n","    !spleeter separate -o /content/drive/MyDrive/Task/audioout/ /content/drive/MyDrive/Task/A2.mp3 #for video2\n","    !spleeter separate -o /content/drive/MyDrive/Task/audioout/ /content/drive/MyDrive/Task/A3.mp3 #for video3\n","    !spleeter separate -o /content/drive/MyDrive/Task/audioout/ /content/drive/MyDrive/Task/A4.mp3 #for video4\n","    print(\"Done create audio>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n","\n","def speech_to_txt():\n","    import speech_recognition as sr \n","    import os \n","    import shutil\n","    from pydub import AudioSegment\n","    from pydub.silence import split_on_silence\n","\n","    # create a speech recognition object\n","    r = sr.Recognizer()\n","    paths = [\"/content/drive/MyDrive/Task/audioout/A0/vocals.wav\",\"/content/drive/MyDrive/Task/audioout/A1/vocals.wav\",\"/content/drive/MyDrive/Task/audioout/A2/vocals.wav\",\"/content/drive/MyDrive/Task/audioout/A3/vocals.wav\",\"/content/drive/MyDrive/Task/audioout/A4/vocals.wav\"]#\n","    txt=['A0','A1','A2','A3','A4']#\n","\n","    # a function that splits the audio file into chunks\n","    # and applies speech recognition\n","    def get_large_audio_transcription(path):\n","        \"\"\"\n","        Splitting the large audio file into chunks\n","        and apply speech recognition on each of these chunks\n","        \"\"\"\n","        count=0\n","        # open the audio file using pydub\n","        sound = AudioSegment.from_wav(path)  \n","        # split audio sound where silence is 700 miliseconds or more and get chunks\n","        chunks = split_on_silence(sound,\n","            # experiment with this value for your target audio file\n","            min_silence_len = 500,\n","            # adjust this per requirement\n","            silence_thresh = sound.dBFS-16,\n","            # keep the silence for 1 second, adjustable as well\n","            keep_silence=500,\n","        )\n","        folder_name = \"/content/drive/MyDrive/Task/audioout/\"+txt[count]+\"/audio-chunks\"\n","        count+=1\n","        # create a directory to store the audio chunks\n","        if not os.path.isdir(folder_name):\n","            os.mkdir(folder_name)\n","        whole_text = \"\"\n","        # process each chunk \n","        for i, audio_chunk in enumerate(chunks, start=1):\n","            # export audio chunk and save it in\n","            # the `folder_name` directory.\n","            chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n","            audio_chunk.export(chunk_filename, format=\"wav\")\n","            # recognize the chunk\n","            with sr.AudioFile(chunk_filename) as source:\n","                audio_listened = r.record(source)\n","                # try converting it to text\n","                try:\n","                    text = r.recognize_google(audio_listened)\n","                except sr.UnknownValueError as e:\n","                    print(\"Error:\", str(e))\n","                else:\n","                    text = f\"{text.capitalize()}. \"\n","                    print(chunk_filename, \":\", text)\n","                    whole_text += text\n","        # return the text for all chunks detected\n","        return whole_text\n","\n","    #print(\"\\nFull text:\", get_large_audio_transcription(path))\n","    if os.path.exists('/content/drive/MyDrive/Task/text'):\n","        shutil.rmtree('/content/drive/MyDrive/Task/text')\n","    os.mkdir('/content/drive/MyDrive/Task/text')\n","    counter=0\n","    for path in paths:\n","        result1 = (get_large_audio_transcription(path))\n","        with open('/content/drive/MyDrive/Task/text/'+txt[counter]+'.txt',mode ='w') as file: \n","            file.write(\":\") \n","            file.write(\"\\n\") \n","            file.write(result1) \n","            print(\"ready!\")\n","        counter+=1\n","    print(\"Done speech to text>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n","    global ana_status\n","    ana_status=ana_status+1\n","\n","    \n","def random_color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):\n","    h = int(360.0 * 45.0 / 255.0)\n","    s = int(100.0 * 255.0 / 255.0)\n","    l = int(100.0 * float(random_state.randint(60, 120)) / 255.0)\n","\n","    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n","\n","def word_cloud():\n","    text_files =[]\n","    all_text = \"/content/drive/MyDrive/Task/text\"\n","    os.chdir(all_text)\n","\n","    # iterate through all file\n","    for file in os.listdir():\n","        # Check whether file is in text format or not\n","        if file.endswith(\".txt\"):\n","            file_path = f\"{all_text}/{file}\"\n","            #print(file_path)\n","            text_files.append(file_path)\n","\n","    text_files\n","\n","    for txt in range(0,len(text_files)):\n","        temp1 = text_files[txt]\n","        file_content=open (temp1).read()\n","        #file_content= read_text_file(temp1)\n","        print(file_content)\n","        wordcloud = WordCloud(font_path = r'/content/drive/MyDrive/Task/verdana/verdana/verdana.ttf',\n","                                    stopwords = STOPWORDS,\n","                                    background_color = 'green',\n","                                    width = 1200,\n","                                    height = 1000,\n","                                    color_func = random_color_func).generate(file_content)\n","\n","        plt.imshow(wordcloud)\n","        plt.axis('off')\n","        plt.savefig(path.join(all_text,\"V{0}.png\".format(txt)))\n","        plt.show()\n","        print(\"done Word cloud>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n","        global ana_status\n","        ana_status=ana_status+1\n","        return\n","\n","\n","#trends\n","def trends(location,product_name):\n","    \n","    pytrends = TrendReq(hl='en-US', tz=360)\n","    #user input\n","    Location = str(location).lower().replace(\" \",\"_\")\n","\n","    #trends\n","\n","    pytrend = TrendReq()\n","    # Get realtime Google Trends data\n","    df = pytrend.trending_searches(pn= Location)\n","    print(\"Top Trends in the country\")\n","    print(df[:5])\n","\n","\n","    #save to csv\n","    #allqueries.to_csv('allqueries.csv')\n","\n","    #download from collab\n","    #files.download(\"allqueries.csv\")\n","\n","    #provide your search terms\n","    Input_keyword = product_name.split('+')[0]\n","    kw_list=[Input_keyword]\n","\n","    pytrend.build_payload(kw_list=kw_list, geo= 'US')\n","\n","\n","    #get related queries\n","    related_queries = pytrend.related_queries()\n","    related_queries.values()\n","\n","    #build lists dataframes\n","\n","    top = list(related_queries.values())[0]['top']\n","    rising = list(related_queries.values())[0]['rising']\n","\n","    #convert lists to dataframes\n","\n","    dftop = pd.DataFrame(top)\n","    dfrising = pd.DataFrame(rising)\n","\n","    #join two data frames\n","    joindfs = [dftop, dfrising]\n","    allqueries = pd.concat(joindfs, axis=1)\n","\n","    #function to change duplicates\n","\n","    cols=pd.Series(allqueries.columns)\n","    for dup in allqueries.columns[allqueries.columns.duplicated(keep=False)]: \n","        cols[allqueries.columns.get_loc(dup)] = ([dup + '.' + str(d_idx) \n","                                        if d_idx != 0 \n","                                        else dup \n","                                        for d_idx in range(allqueries.columns.get_loc(dup).sum())]\n","                                        )\n","    allqueries.columns=cols\n","\n","    #rename to proper names\n","\n","    allqueries.rename({'query': 'top query', 'value': 'top query value', 'query.1': 'related query', 'value.1': 'related query value'}, axis=1, inplace=True) \n","\n","    #check your dataset\n","    print(\"Product related Queries \")\n","    print(allqueries['related query'][:10])\n","    print(type(df[:5]))\n","    s=allqueries['related query'][:10]\n","    s=s.to_frame().reset_index()\n","    s = s.rename(columns= {0: 'list'})\n","    s.index.name = 'index'\n","\n","    table1=[df[:5].to_html(classes='data', header=\"true\")]\n","    table2=[s.to_html(classes='data', header=\"true\")]\n","    \n","    global ana_status\n","    ana_status=ana_status+1\n","    return table1,table2\n","\n","\n","#create folder visualization\n","if os.path.exists('/content/drive/MyDrive/Task/Visualization'):\n","        shutil.rmtree('/content/drive/MyDrive/Task/Visualization')\n","os.mkdir('/content/drive/MyDrive/Task/Visualization')\n","\n","\n","\n","def obj_vis():\n","    \n","\n","    obj_df1 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_1.xlsx', \"Object\")\n","    obj_df2 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_2.xlsx', \"Object\")\n","    obj_df3 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_3.xlsx', \"Object\")\n","    obj_df4 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_4.xlsx', \"Object\")\n","    obj_df5 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_5.xlsx', \"Object\")\n","\n","    #genage_df1 = pd.read_excel(r'/content/drive/MyDrive/Recommendation/Folder_1.xlsx', \"Gender\")\n","    #sent_df1 = pd.read_excel(r'/content/drive/MyDrive/Recommendation/Emotions_Folder_1.xlsx', \"Sentiment\")\n","    #text_df1 = pd.read_excel(r'/content/drive/MyDrive/Recommendation/Folder_1.xlsx', \"Color\")\n","\n","    ax = obj_df1['object_name'].value_counts().plot(kind='bar',\n","                                        figsize=(12,5),\n","                                        title=\"Video 1_Number of Unique Objects\", rot='0')\n","    ax.set_xlabel(\"Objects\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V1_obj.png')\n","\n","    ax = obj_df2['object_name'].value_counts().plot(kind='bar',\n","                                        figsize=(12,5),\n","                                        title=\"Video 2_Number of Unique Objects\", rot='0')\n","    ax.set_xlabel(\"Objects\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V2_obj.png')\n","\n","    ax = obj_df3['object_name'].value_counts().plot(kind='bar',stacked = True,\n","                                        figsize=(12,5),\n","                                        title=\"Video 3_Number of Unique Objects\", rot='0')\n","    ax.set_xlabel(\"Objects\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V3_obj.png')\n","\n","    ax = obj_df4['object_name'].value_counts().plot(kind='bar',\n","                                        figsize=(12,5),\n","                                        title=\"Video 4_Number of Unique Objects\", rot='0')\n","    ax.set_xlabel(\"Objects\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V4_obj.png')\n","\n","    ax = obj_df5['object_name'].value_counts().plot(kind='bar',\n","                                        figsize=(12,5),\n","                                        title=\"Video 5_Number of Unique Objects\", rot='0')\n","    ax.set_xlabel(\"Objects\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V5_Obj.png')\n","\n","    obj1 = obj_df1['object_name'].value_counts()\n","    obj2 = obj_df2['object_name'].value_counts()\n","    obj3 = obj_df3['object_name'].value_counts()\n","    obj4 = obj_df4['object_name'].value_counts()\n","    obj5 = obj_df5['object_name'].value_counts()\n","\n","    v1 = len(obj_df1['object_name'])\n","    v2 = len(obj_df2['object_name'])\n","    v3 = len(obj_df3['object_name'])\n","    v4 = len(obj_df4['object_name'])\n","    v5 = len(obj_df5['object_name'])\n","\n","    df1 = [{v1,v2,v3,v4,v5}]\n","    df1 ={'videos':['v1','v2','v3','v4','v5'], 'objc':[v1,v2,v3,v4,v5]}\n","    df2 = pd.DataFrame(df1)\n","    df3 = df2.objc\n","    print(df2)\n","\n","    #obj message for video 1 and 4\n","    if df3[0] >= df3[3] :\n","        obj_msg1=(f\"Video 1 has Higher Number of Objects on Count compared with Video 4 : \\nobjects : v1:{v1} v4:{v4}\")\n","        print(f\"Video 1 has Higher Number of Objects on Count compared with Video 4 : \\nobjects : v1:{v1} v4:{v4}\")\n","    else:\n","        obj_msg1=(f\"Video 4 has Higher Number of Objects on Count compared with Video 1 : \\nobjects : v1:{v1} v4:{v4}\")\n","        print(f\"Video 4 has Higher Number of Objects on Count compared with Video 1 : \\nobjects : v1:{v1} v4:{v4}\")\n","    #obj message for video 2 and 4\n","    if df3[1] >= df3[3] :\n","        obj_msg2=(f\"Video 2 has Higher Number of Objects on Count compared with Video 4 :\\nobjects : v2:{v2} v4:{v4}\")\n","        print(f\"Video 2 has Higher Number of Objects on Count compared with Video 4 :\\nobjects : v2:{v2} v4:{v4}\")\n","    else:\n","        obj_msg2=(f\"Video 4 has Higher Number of Objects on Count compared with Video 2 :\\nobjects : v2:{v2} v4:{v4}\")\n","        print(f\"Video 4 has Higher Number of Objects on Count compared with Video 2 :\\nobjects : v2:{v2} v4:{v4}\")\n","    #obj message for video 3 and 4\n","    if df3[2] >= df3[3] :\n","        obj_msg3=(f\"Video 3 has Higher Number of Objects on Count compared with Video 4 :\\nobjects : v1:{v3} v4:{v4}\")\n","        print(f\"Video 3 has Higher Number of Objects on Count compared with Video 4 :\\nobjects : v1:{v3} v4:{v4}\")\n","    else:\n","        obj_msg3 = (f\"Video 4 has Higher Number of Objects on Count compared with Video 3 :\\nobjects : v3:{v3} v4:{v4}\")\n","        print(f\"Video 4 has Higher Number of Objects on Count compared with Video 3 :\\nobjects : v3:{v3} v4:{v4}\")\n","    obj_msg=[obj_msg1,obj_msg2,obj_msg3]\n","\n","    global ana_status\n","    ana_status=ana_status+1\n","\n","\n","\n","def gender():\n","  gen_df1 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_1.xlsx', \"Gender\")\n","  gen_df2 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_2.xlsx', \"Gender\")\n","  gen_df3 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_3.xlsx', \"Gender\")\n","  gen_df4 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_4.xlsx', \"Gender\")\n","  gen_df5 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_5.xlsx', \"Gender\")\n","\n","  #genage_df1 = pd.read_excel(r'/content/drive/MyDrive/Recommendation/Folder_1.xlsx', \"Gender\")\n","  #sent_df1 = pd.read_excel(r'/content/drive/MyDrive/Recommendation/Emotions_Folder_1.xlsx', \"Sentiment\")\n","  #text_df1 = pd.read_excel(r'/content/drive/MyDrive/Recommendation/Folder_1.xlsx', \"Color\")\n","  gen_df1 = gen_df1.dropna()\n","  gen_df2 = gen_df2.dropna()\n","  gen_df3 = gen_df3.dropna()\n","  gen_df4 = gen_df4.dropna()\n","  gen_df5 = gen_df5.dropna()\n","\n","  v1_g_m = sum(gen_df1.gender_name == 'Male')\n","  v1_g_f = sum(gen_df1.gender_name == 'Female')\n","  v2_g_m = sum(gen_df2.gender_name == 'Male')\n","  v2_g_f = sum(gen_df2.gender_name == 'Female')\n","  v3_g_m = sum(gen_df3.gender_name == 'Male')\n","  v3_g_f = sum(gen_df3.gender_name == 'Female')\n","  v4_g_m = sum(gen_df4.gender_name == 'Male')\n","  v4_g_f = sum(gen_df4.gender_name == 'Female')\n","  v5_g_m = sum(gen_df5.gender_name == 'Male')\n","  v5_g_f = sum(gen_df5.gender_name == 'Female')\n","\n","  ax = gen_df1['gender_name'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 1_ Gener Classification\", rot='0')\n","  ax.set_xlabel(\"Gender\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V1_gen.png')\n","\n","  ax = gen_df1['age_group'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 1_Age Distribution\", rot='0')\n","  ax.set_xlabel(\"Ages\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V1_Age.png')\n","\n","  bb3 = pd.pivot_table(gen_df1, index=['age_group'], columns=['gender_name'], values=['gender_frame'], aggfunc='count')\n","  bb3\n","  plt.figure(); \n","  bb3.plot.bar(title='Fig.No. 4 : STACKED BAR CHART', stacked=True); \n","  plt.xlabel('Age Group'); plt.ylabel('Gender') \n","\n","  plt.figure(); \n","  bb3.plot.bar(title='Fig.No. 4 : STACKED BAR CHART', stacked=True); \n","  plt.xlabel('Age Group'); plt.ylabel('Gender') \n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/stacked_bar.png')\n","\n","  ax = gen_df2['gender_name'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 2_Gender Classification\", rot='0')\n","  ax.set_xlabel(\"Gender\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V2_gen.png')\n","\n","  ax = gen_df2['age_group'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 2_Age Distribution\", rot='0')\n","  ax.set_xlabel(\"Age\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V2_age.png')\n","\n","  ax = gen_df3['gender_name'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 3_Gender Classification\", rot='0')\n","  ax.set_xlabel(\"Gender\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V3_gen.png')\n","\n","  ax = gen_df3['age_group'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 3_Age Distribution\", rot='0')\n","  ax.set_xlabel(\"Age\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V3_age.png')  \n","\n","  ax = gen_df4['gender_name'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 4_Gender Classification\", rot='0')\n","  ax.set_xlabel(\"Gender\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V4_gen.png')  \n","\n","  ax = gen_df4['age_group'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 4_Age Distribution\", rot='0')\n","  ax.set_xlabel(\"Age\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V4_age.png')\n","\n","  ax = gen_df5['gender_name'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 4_Gender Classification\", rot='0')\n","  ax.set_xlabel(\"Gender\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V5_gen.png')\n","\n","  ax = gen_df5['age_group'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 4_Age Distribution\", rot='0')\n","  ax.set_xlabel(\"Age\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V5_age.png')\n","\n","\n","  v1_a = gen_df1['age_group'].value_counts()\n","  v2_a = gen_df2['age_group'].value_counts()\n","  v3_a = gen_df3['age_group'].value_counts()\n","  v4_a = gen_df4['age_group'].value_counts()\n","  v5_a = gen_df5['age_group'].value_counts()\n","\n","\n","  if v1_g_m >= v5_g_m :\n","    s1=(\"Video 1 has Higher Number of Male on Count compared with Video 5 : \"   )\n","    ss1=(f'Gender : V1_Male:{v1_g_m}  V5_Male:{v5_g_m} '  )\n","  else:\n","      s1=print(\"Video 5 has Higher Number of Male on Count compared with Video 1 : \"   )\n","      ss1=print(f'Gender : V1_Male:{v1_g_m}  V5_Male:{v5_g_m} '  )\n","\n","  if v1_g_f >= v5_g_f :\n","    s2=(\"Video 1 has Higher Number of Female on Count compared with Video 5 : \"   )\n","    ss2=(f'Gender : V1_Female:{v1_g_f}  V5_Female:{v5_g_f} '  )\n","  else:\n","      s2=(\"Video 5 has Higher Number of Female on Count compared with Video 1 : \"   )\n","      ss2=(f'Gender : V1_Female:{v1_g_f}  V5_Female:{v5_g_f} '  )\n","  \n","  if v2_g_m >= v5_g_m :\n","    s3=(\"Video 2 has Higher Number of Male on Count compared with Video 5 : \"   )\n","    ss3=(f'Gender : V2_Male:{v2_g_m}  V5_Male:{v5_g_m} '  )\n","  else:\n","      s3=(\"Video 5 has Higher Number of Male on Count compared with Video 2 : \"   )\n","      ss3=(f'Gender : V2_Male:{v2_g_m}  V5_Male:{v5_g_m} '  )\n","  \n","  if v2_g_f >= v5_g_f :\n","    s4=(\"Video 2 has Higher Number of Female on Count compared with Video 5 : \"   )\n","    ss4=(f'Gender : V2_Female:{v2_g_f}  V5_Female:{v5_g_f} '  )\n","  else:\n","      s4=(\"Video 5 has Higher Number of Female on Count compared with Video 2 : \"   )\n","      ss4=(f'Gender : V2_Female:{v2_g_f}  V5_Female:{v5_g_f} '  )\n","  \n","  if v3_g_m >= v5_g_m :\n","    s5=(\"Video 3 has Higher Number of Male on Count compared with Video 5 : \"   )\n","    ss5=(f'Gender : V3_Male:{v3_g_m}  V5_Male:{v5_g_m} '  )\n","  else:\n","      s5=(\"Video 5 has Higher Number of Male on Count compared with Video 3 : \"   )\n","      ss5=(f'Gender : V3_Male:{v3_g_m}  V5_Male:{v5_g_m} '  )\n","\n","  if v3_g_f >= v5_g_f :\n","    s6=(\"Video 3 has Higher Number of Female on Count compared with Video 5 : \"   )\n","    ss6=(f'Gender : V3_Female:{v3_g_f}  V5_Female:{v5_g_f} '  )\n","  else:\n","      s6=(\"Video 5 has Higher Number of Female on Count compared with Video 3 : \"   )\n","      ss6=(f'Gender : V3_Female:{v3_g_f}  V5_Female:{v5_g_f} '  )\n","  \n","  if v4_g_m >= v5_g_m :\n","    s7=(\"Video 4 has Higher Number of Male on Count compared with Video 5 : \"   )\n","    ss7=(f'Gender : V4_Male:{v4_g_m}  V5_Male:{v5_g_m} '  )\n","  else:\n","      s7=(\"Video 5 has Higher Number of Male on Count compared with Video 4 : \"   )\n","      ss7=(f'Gender : V4_Male:{v4_g_m}  V5_Male:{v5_g_m} '  )\n","  \n","  if v4_g_f >= v5_g_f :\n","    s8=(\"Video 4 has Higher Number of Female on Count compared with Video 5 : \"   )\n","    ss8=(f'Gender : V4_Female:{v4_g_f}  V5_Female:{v5_g_f} '  )\n","  else:\n","      s8=(\"Video 5 has Higher Number of Female on Count compared with Video 4 : \"   )\n","      ss8=(f'Gender : V4_Female:{v4_g_f}  V5_Female:{v5_g_f} '  )\n","\n","  a= v1_a[:1,]\n","  b= v2_a[:1,]\n","  c= v3_a[:1,]\n","  d= v4_a[:1,]\n","  e = v5_a[:1,]\n","\n","  df1 ={'videos':['v1','v2','v3','v4','v5'], 'ages':[a,b,c,d,e]}\n","  df2 = pd.DataFrame(df1)\n","\n","  ax = df2['ages'].value_counts().plot(kind='bar',\n","                                    figsize=(8,5),\n","                                    title=\"Comparision - Diversity\", rot='0')\n","  ax.set_xlabel(\"videos\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/finalages.png')\n","\n","  df2['ages'] = df2['ages'].astype(float)\n","  df2.ages = pd.to_numeric(df2.ages)\n","  ax = df2.plot.bar(x='videos', y='ages', rot=0)\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/videos_ages.png')\n","\n","  ax = df2.plot.bar(x='videos', y='ages', rot=0)\n","  global ana_status\n","  ana_status=ana_status+1\n","  return\n","\n","\n","\n","def color():\n","    \n","\n","    #read excel files\n","    clr_df1 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_1.xlsx', \"Color\")\n","    clr_df2 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_2.xlsx', \"Color\")\n","    clr_df3 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_3.xlsx', \"Color\")\n","    clr_df4 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_4.xlsx', \"Color\")\n","    clr_df5 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_5.xlsx', \"Color\")\n","\n","    #CREATE PLOTS\n","    #video1\n","    ax = clr_df1['color_name'].value_counts().plot(kind='bar',\n","                                        figsize=(8,4),\n","                                        title=\"Video 1 - Diversity\", rot='0')\n","    ax.set_xlabel(\"Color\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V1_Clr.png')\n","\n","    #video2\n","    ax = clr_df2['color_name'].value_counts().plot(kind='bar',\n","                                        figsize=(12,6),\n","                                        title=\"Video 2 - Diversity\", rot='0')\n","    ax.set_xlabel(\"Color\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V2_Clr.png')\n","\n","    #video3\n","    ax = clr_df3['color_name'].value_counts().plot(kind='bar',\n","                                        figsize=(12,6),\n","                                        title=\"Video 3 - Diversity\", rot='0')\n","    ax.set_xlabel(\"Color\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V3_Clr.png')\n","\n","    #video4\n","    ax = clr_df4['color_name'].value_counts().plot(kind='bar',\n","                                        figsize=(8,5),\n","                                        title=\"Video 4 - Diversity\", rot='0')\n","    ax.set_xlabel(\"Color\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V4_Clr.png')\n","\n","    #video5\n","    ax = clr_df5['color_name'].value_counts().plot(kind='bar',\n","                                        figsize=(8,5),\n","                                        title=\"Video 5 - Diversity\", rot='0')\n","    ax.set_xlabel(\"Color\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V5_Clr.png')\n","\n","    clr1 = clr_df1['color_name'].value_counts()\n","    clr2 = clr_df2['color_name'].value_counts()\n","    clr3 = clr_df3['color_name'].value_counts()\n","    clr4 = clr_df4['color_name'].value_counts()\n","    clr5 = clr_df5['color_name'].value_counts()\n","\n","    a= clr1[:2,]\n","    b= clr2[:2,]\n","    c= clr3[:2,]\n","    d= clr4[:2,]\n","    e= clr5[:2,]\n","\n","    df1 ={'videos':['v1','v2','v3','v4','v5'], 'clr':[a,b,c,d,e]}\n","    df2 = pd.DataFrame(df1)\n","    ax = df2['clr'].value_counts().plot(kind='bar',\n","                                        figsize=(8,5),\n","                                        title=\"Video 4 - Diversity\", rot='0')\n","    ax.set_xlabel(\"videos\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V6_Clr.png')\n","    global ana_status\n","    ana_status=ana_status+1\n","    return\n","\n","\n","def emotion():\n","\n","    #read excel files\n","    em_df1 = pd.read_excel(r'/content/drive/MyDrive/Task/Emotions_Folder_1.xlsx', \"Emotions\")\n","    em_df2 = pd.read_excel(r'/content/drive/MyDrive/Task/Emotions_Folder_2.xlsx', \"Emotions\")\n","    em_df3 = pd.read_excel(r'/content/drive/MyDrive/Task/Emotions_Folder_3.xlsx', \"Emotions\")\n","    em_df4 = pd.read_excel(r'/content/drive/MyDrive/Task/Emotions_Folder_4.xlsx', \"Emotions\")\n","    em_df5 = pd.read_excel(r'/content/drive/MyDrive/Task/Emotions_Folder_5.xlsx', \"Emotions\")\n","\n","    #CREATE PLOTS\n","    em_df1 = em_df1.rename(columns = {\"Unnamed:0\" : \"level\"})\n","\n","    #video1\n","    ex = em_df1.plot(x=\"Human Emotions\", y=[\"Emotion Value\"], kind=\"bar\",  color=\"C2\" , figsize=(8,4),\n","                                        title=\"Emotions in Video 1\", rot='0')  \n","\n","    ex.set_xlabel(\"Human Emotions\")\n","    ex.set_ylabel(\"Emotion Level in Entire Video\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V1_Emotion.png')\n","\n","    #video2\n","    ex = em_df2.plot(x=\"Human Emotions\", y=[\"Emotion Value\"], kind=\"bar\",  color=\"C2\" , figsize=(8,4),\n","                                        title=\"Emotions in Video 2\", rot='0')  \n","\n","    ex.set_xlabel(\"Human Emotions\")\n","    ex.set_ylabel(\"Emotion Level in Entire Video\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V2_Emotion.png')\n","\n","    #video3\n","    ex = em_df3.plot(x=\"Human Emotions\", y=[\"Emotion Value\"], kind=\"bar\",  color=\"C2\" , figsize=(8,4),\n","                                        title=\"Emotions in Video 3\", rot='0')  \n","\n","    ex.set_xlabel(\"Human Emotions\")\n","    ex.set_ylabel(\"Emotion Level in Entire Video\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V3_Emotion.png')\n","    \n","    #video4\n","    ex = em_df4.plot(x=\"Human Emotions\", y=[\"Emotion Value\"], kind=\"bar\",  color=\"C2\" , figsize=(8,4),\n","                                        title=\"Emotions in Video 4\", rot='0')  \n","\n","    ex.set_xlabel(\"Human Emotions\")\n","    ex.set_ylabel(\"Emotion Level in Entire Video\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V4_Emotion.png')\n","\n","    #video5\n","    ex = em_df5.plot(x=\"Human Emotions\", y=[\"Emotion Value\"], kind=\"bar\",  color=\"C2\" , figsize=(8,4),\n","                                        title=\"Emotions in Video 5\", rot='0')  \n","\n","    ex.set_xlabel(\"Human Emotions\")\n","    ex.set_ylabel(\"Emotion Level in Entire Video\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V5_Emotion.png')\n","    \n","    global ana_status\n","    ana_status=ana_status+1\n","\n","\n","\n","def music():\n","\n","    music_df1 = pd.read_excel(r'/content/drive/MyDrive/Task/Music_type.xlsx', \"music output\")\n","\n","    mx = music_df1['Music_out'].value_counts().plot(kind='bar', color = \"C4\",\n","                                        figsize=(12,5),\n","                                        title=\"Music From Videos\", rot='0', )\n","    mx.set_xlabel(\"Music Types from V1, V2, V3, V4, V5\")\n","    mx.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/music1.png')\n","    global ana_status\n","    ana_status=ana_status+1\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Sl1HHiJOGNHJ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"0VxiPTiSAklV"},"source":["###**FLASK**"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":560,"status":"ok","timestamp":1661776633337,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"MoD0iPWLOmyd","outputId":"670c201c-cdef-4e55-90a4-cd2b8027cc1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"]}],"source":["!ngrok authtoken 27hMUYstXU9FbCK7ejYIWnDwu3g_3Bt3PL1LoHseoRkPySH5A"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Krk8haDxuQ36","outputId":"2c609fe6-ae80-40d9-f06e-ba4667340cb4"},"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"]},{"output_type":"stream","name":"stdout","text":[" * Running on http://f030-35-194-212-109.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [29/Aug/2022 12:37:36] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [29/Aug/2022 12:37:37] \"\u001b[33mGET /style.css HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [29/Aug/2022 12:37:38] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [29/Aug/2022 12:37:46] \"\u001b[32mPOST /submit HTTP/1.1\u001b[0m\" 302 -\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION>>>>>>>>>>>>> india\n","video1.mp4\n","video2.mp4\n","video3.mp4\n","video4.mp4\n","video0.mp4\n","https://www.youtube.com/watch?v=d_ry4SYTYZs\n","[youtube] d_ry4SYTYZs: Downloading webpage\n","[download] Resuming download at byte 12411479\n","[download] Destination: OPPO Diwali 2021 _ Light Up New Beginnings-d_ry4SYTYZs.f137.mp4\n","[download]  56.3% of 22.15MiB at 73.78KiB/s ETA 02:14"]}],"source":["#!pip install flask-ngrok\n","#!pip install youtube_dl\n","#!curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list && sudo apt update && sudo apt install ngrok   \n","\n","#######################################################################################################\n","\n","#GLOBAL VARIABLES\n","video_links=[]\n","status=0\n","ana_status=0\n","keyword=''\n","location=''\n","\n","\n","def frame():\n","    #sleep(1)\n","    print(\"creating frames>>>>>>>>>>>>>>>\")\n","    rem_path = 'save'\n","    dir = rem_path\n","    if os.path.exists(dir):\n","        shutil.rmtree(dir)\n","        os.makedirs(dir)\n","        print(\"removed\")\n","    else:\n","        os.makedirs(dir)\n","        print(\"made\")\n","    \n","    #video_paths=['/content/drive/MyDrive/Task/video.mp4']\n","    video_paths = glob(r\"/content/drive/MyDrive/Task/*.mp4\")\n","    print(video_paths)\n","    skip_n_frames = 15\n","    save_dir = \"save\"\n","    for path in video_paths:\n","        name = path.split(\"/\")[-1].split(\".\")[0]\n","        print(name)\n","        save_path = os.path.join(save_dir, name)\n","        print(save_path)\n","        if not os.path.exists(save_path):\n","            os.makedirs(save_path)\n","        \n","        count = 0\n","        cap = cv2.VideoCapture(path)\n","\n","        while True:\n","            ret, frame = cap.read()\n","            if ret == False:\n","                cap.release()\n","                break\n","            if count % skip_n_frames == 0:\n","                cv2.imwrite(f\"{save_path}/{count}.jpg\", frame)\n","\n","            count += 1\n","\n","    print(\"Done>>>>>>>>>>>>>>>>>>frames\")\n","    global ana_status\n","    ana_status=ana_status+1\n","    \n","    return \n","\n","#######################################################################s#########################\n","\n","def task(search_keyword):\n","    sleep(1)\n","    global status\n","    status=0\n","    import urllib.request\n","    import re\n","    import os\n","    import glob\n","    import pandas as pd\n","    import youtube_dl\n","    from glob import glob\n","    \n","    target = r'/content/drive/MyDrive/Task/'\n","\n","    for x in os.listdir(target):\n","                if x.endswith('.mp4'):\n","                    print(x)\n","                    os.unlink(target + x)\n","\n","            #download benchmark videos\n","            #search_keyword = input(\"Keyword: \")\n","    video_lnk=[]\n","    URLL=\"https://www.youtube.com/results?search_query=\"+search_keyword+\"&sp=CAMSBggFEAEYAQ%253D%253D\"\n","    html =urllib.request.urlopen(URLL)\n","    video_ids = re.findall(r\"watch\\?v=(\\S{11})\", html.read().decode())\n","    video_ids = video_ids[0:4]\n","    global video_links\n","    for vid in video_ids : \n","        video_lnk.append(f\"https://www.youtube.com/watch?v=\" + vid)\n","\n","    for i in range(len(video_lnk)):\n","        url= video_lnk[i]\n","        print(url)       \n","        ydl_opts = {\n","            'nooverwrites': True,\n","            'format':'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best'\n","        }\n","        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n","            ydl.download([url])\n","            \n","        print(\"successfully\")\n","        video_links.append(url)\n","        i=i+1\n","        if i>=4:\n","            break\n","\n","    path = glob(r\"/content/drive/MyDrive/Task/*.mp4\")\n","    i=1\n","    print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>',path)\n","    for file in path:\n","        src = file\n","        dst = \"video\"+str(i)+\".mp4\"\n","        os.rename(src,dst)\n","        i+=1  \n","    status = status +1\n","    print(status)\n","    print(video_lnk)\n","    global allow_upload\n","    allow_upload=1\n","    return      \n","\n","#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>FLASK APP>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>FLASK APP>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","app = Flask(__name__,template_folder='/content/drive/MyDrive/Task/templates',static_folder='/content/drive/MyDrive/Task/Visualization')#__name__ is the wsgi application\n","\n","run_with_ngrok(app)\n","\n","@app.route('/')\n","def welcome():\n","    global status\n","    status=0\n","    msg='Please click Submit button to start downloading benchmark video'\n","    return render_template('Findex1.html',status=status)\n","\n","\n","@app.route('/submit',methods=['POST','GET'])\n","def submit():\n","    rec='recommend'\n","    if request.method=='POST':\n","        keyword=request.form['keyword']\n","        location=request.form['location']\n","        print('LOCATION>>>>>>>>>>>>>',location)\n","        # location='india'\n","        return redirect(url_for(rec,search_keyword=keyword))\n","\n","@app.route('/recommend/<search_keyword>')\n","def recommend(search_keyword):\n","    # task_thr = Thread(target=task,args=[search_keyword])\n","    # task_thr.start()\n","    task(search_keyword)\n","    # urls=task(search_keyword)\n","    # video_lnk=task(search_keyword)\n","    return render_template('Findex1.html')\n","\n","@app.route('/status_download', methods=['POST','GET'])\n","def status_download():\n","  if request.method == 'POST':\n","    count=len(video_links)\n","  return render_template('Findex1.html',urls=video_links,count=count,status=status)\n","\n","#a button can be used to refresh page and display upload button if the video is downloaded \n","\n","\n","@app.route('/upload', methods=['POST','GET'])\n","def upload():\n","      if request.method == 'POST':\n","        # if ana_status==0:\n","        #     return render_template('index.html',msg='Downloading videos please wait')\n","        key = request.files['video']\n","        key.filename='video0'\n","        key.save(r'/content/drive/MyDrive/Task/'+key.filename+'.mp4')\n","        global status\n","        status = 2\n","        print('upload===',status)\n","        print(video_links)\n","        msg=\"Successfully uploaded video as video0\"       \n","        return render_template('Findex1.html',status=status,msg=msg,msg11='List of downloaded videos',data1=video_links[0],data2=video_links[1],data3=video_links[2],data4=video_links[3])\n","\n","@app.route('/analyze', methods=['POST','GET'])\n","def analyze():\n","  if request.method == 'POST':\n","    frame()\n","    ana()\n","    face()\n","    create_audio()\n","    speech_to_txt()\n","    word_cloud()\n","    df1,df2=trends(location,keyword)\n","    obj_vis()\n","    gender()\n","    color()\n","    emotion()\n","    return render_template('Findex1.html',table1=df1,table2=df2,ana_status=ana_status,urls=video_links)\n","\n","#checks status of ana and frame as they are different threads \n","@app.route('/status', methods=['POST','GET'])\n","def status():\n","    if request.method == 'POST':\n","        status = 3\n","        count=len(video_links)\n","        return render_template('Findex1.html',ana_status=ana_status,urls=video_links,count=count,status=status)\n","\n","\n","@app.route('/results', methods=['POST','GET'])\n","def obj():\n","    if request.method=='POST':\n","        object_path=['V1_obj.png','V2_obj.png','V3_obj.png','V4_obj.png','V5_obj.png']\n","        gender_path=['V1_Age.png','V1_gen.png','V2_age.png','V2_gen.png','V3_age.png','V3_gen.png','V4_age.png','V4_gen.png','V5_age.png','V5_gen.png','finalages.png','stacked_bar.png','videos_ages.png']\n","        color_path=['V1_Clr.png','V2_Clr.png','V3_Clr.png','V4_Clr.png','V5_Clr.png','V6_Clr.png']\n","        emotion_path=['V1_Emotion.png','V2_Emotion.png','V3_Emotion.png','V4_Emotion.png','V5_Emotion.png']\n","        music_path=['music1.png']\n","        return render_template(\"output.html\", object_path=object_path,gender_path=gender_path,color_path=color_path,emotion_path=emotion_path,music_path=music_path)\n","\n","\n","\n","if __name__ == '__main__' :\n","    app.run()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IKoGJYu_m3em"},"outputs":[],"source":["'''video_files = glob(r\"/content/drive/MyDrive/Task/*.mp4\")\n","len(video_files)\n","\n","vidf=video_files[1:]\n","vidf.append(video_files[0])\n","\n","# from mtcnn import MTCNN\n","face_detector = FER(mtcnn=True)\n","for vid in range(0,len(video_files)):\n","    temp1 = vidf[vid]\n","    input_video = Video(temp1)\n","    processing_data = input_video.analyze(face_detector, display=False)\n","    vid_df = input_video.to_pandas(processing_data)\n","    vid_df = input_video.get_first_face(vid_df)\n","    vid_df = input_video.get_emotions(vid_df)\n","    angry = sum(vid_df.angry)\n","    disgust = sum(vid_df.disgust)\n","    fear = sum(vid_df.fear)\n","    happy = sum(vid_df.happy)\n","    sad = sum(vid_df.sad)\n","    surprise = sum(vid_df.surprise)\n","    neutral = sum(vid_df.neutral)\n","    emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n","    emotions_values = [angry, disgust, fear, happy, sad, surprise, neutral]\n","    score_comparisons = pd.DataFrame(emotions, columns = ['Human Emotions'])\n","    score_comparisons['Emotion Value'] = [round(x,2) for x in emotions_values]\n","    score_comparisons.sort_values(by = ['Emotion Value'],inplace = True, ascending = False)\n","    print(score_comparisons)\n","    excel_name = \"/content/drive/MyDrive/Task/Emotions_Folder_\" + str(vid+1) + \".xlsx\"\n","    excelfile = pd.ExcelWriter(excel_name)\n","    score_comparisons.to_excel(excelfile, \"Emotions\")\n","    excelfile.save()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SqDVRVYt_YX1"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"master_new.ipynb","provenance":[{"file_id":"14yJCuRSm9UMPpXb1qZD0VMp1FStRFwBN","timestamp":1656424967932}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}