{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25315,"status":"ok","timestamp":1661774786351,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"cP7V-osQp-GM","outputId":"1104e8ee-9313-4596-93c2-20fe35dcb61d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1661774786353,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"1tZaJebCbV_O","outputId":"092c918c-6693-43d5-9721-40b1d72c4301"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Task\n"]}],"source":["cd /content/drive/MyDrive/Task"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"__9QUXhnEEe6","executionInfo":{"status":"ok","timestamp":1661774984338,"user_tz":-330,"elapsed":198000,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"}},"outputId":"b2932141-9944-4354-b9a3-8cbbc7a7880b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting opencv-python==4.5.5.64\n","  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n","\u001b[K     |████████████████████████████████| 60.5 MB 54 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.5.64) (1.21.6)\n","Installing collected packages: opencv-python\n","  Attempting uninstall: opencv-python\n","    Found existing installation: opencv-python 4.6.0.66\n","    Uninstalling opencv-python-4.6.0.66:\n","      Successfully uninstalled opencv-python-4.6.0.66\n","Successfully installed opencv-python-4.5.5.64\n","Found existing installation: imgaug 0.4.0\n","Uninstalling imgaug-0.4.0:\n","  Successfully uninstalled imgaug-0.4.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting imgaug==0.2.5\n","  Downloading imgaug-0.2.5.tar.gz (562 kB)\n","\u001b[K     |████████████████████████████████| 562 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.7.3)\n","Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (0.18.3)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.21.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.15.0)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (3.2.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.9.0)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (7.1.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (1.3.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2021.11.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.6.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (4.1.1)\n","Building wheels for collected packages: imgaug\n","  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imgaug: filename=imgaug-0.2.5-py3-none-any.whl size=561438 sha256=8b98376911a830389342d680b17cbee75fb728440f513635fb9a571991f38217\n","  Stored in directory: /root/.cache/pip/wheels/60/dd/38/d1dc2cad2b6a66dc0249261004990bccb0f27985c74ba26e49\n","Successfully built imgaug\n","Installing collected packages: imgaug\n","Successfully installed imgaug-0.2.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting webcolors\n","  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n","Collecting xlsxwriter\n","  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n","\u001b[K     |████████████████████████████████| 149 kB 5.0 MB/s \n","\u001b[?25hCollecting youtube-dl\n","  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 42.5 MB/s \n","\u001b[?25hCollecting SpeechRecognition\n","  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n","\u001b[K     |████████████████████████████████| 32.8 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n","Collecting ffmpeg\n","  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n","Collecting spleeter\n","  Downloading spleeter-2.3.1-py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 6.2 MB/s \n","\u001b[?25hCollecting fer\n","  Downloading fer-22.4.0-py3-none-any.whl (812 kB)\n","\u001b[K     |████████████████████████████████| 812 kB 47.8 MB/s \n","\u001b[?25hRequirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy) (1.21.6)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.64.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n","Collecting importlib-metadata<4.0.0,>=3.0.0\n","  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n","Collecting norbert==0.2.1\n","  Downloading norbert-0.2.1-py2.py3-none-any.whl (11 kB)\n","Collecting librosa==0.8.0\n","  Downloading librosa-0.8.0.tar.gz (183 kB)\n","\u001b[K     |████████████████████████████████| 183 kB 39.8 MB/s \n","\u001b[?25hCollecting httpx[http2]<0.20.0,>=0.19.0\n","  Downloading httpx-0.19.0-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<=3.19.4 in /usr/local/lib/python3.7/dist-packages (from spleeter) (3.17.3)\n","Requirement already satisfied: pandas<2.0.0,>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from spleeter) (1.3.5)\n","Collecting tensorflow==2.5.0\n","  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n","\u001b[K     |████████████████████████████████| 454.3 MB 15 kB/s \n","\u001b[?25hCollecting llvmlite<0.37.0,>=0.36.0\n","  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n","\u001b[K     |████████████████████████████████| 25.3 MB 1.8 MB/s \n","\u001b[?25hCollecting typer<0.4.0,>=0.3.2\n","  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n","Collecting ffmpeg-python==0.2.0\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Collecting numpy\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","\u001b[K     |████████████████████████████████| 14.8 MB 41.6 MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python==0.2.0->spleeter) (0.16.0)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (3.0.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.7.3)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.0.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.1.0)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (0.4.0)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (0.56.0)\n","Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (0.10.3.post1)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.6.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.1.0)\n","Collecting keras-nightly~=2.5.0.dev\n","  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 36.5 MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.1.2)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.6.3)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (3.1.0)\n","Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (2.8.0)\n","Collecting gast==0.4.0\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting flatbuffers~=1.12.0\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Collecting wrapt~=1.12.1\n","  Downloading wrapt-1.12.1.tar.gz (27 kB)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (0.37.1)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.15.0)\n","Collecting absl-py~=0.10\n","  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 51.8 MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (3.3.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (0.2.0)\n","Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n","  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 53.7 MB/s \n","\u001b[?25hCollecting typing-extensions~=3.7.4\n","  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n","Collecting grpcio~=1.34.0\n","  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 40.9 MB/s \n","\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.0->spleeter) (1.5.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (2022.6.15)\n","Collecting sniffio\n","  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (2.1.0)\n","Collecting rfc3986[idna2008]<2,>=1.3\n","  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n","Collecting httpcore<0.14.0,>=0.13.3\n","  Downloading httpcore-0.13.7-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 6.1 MB/s \n","\u001b[?25hCollecting h2<5,>=3\n","  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 4.1 MB/s \n","\u001b[?25hCollecting hpack<5,>=4.0\n","  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n","Collecting hyperframe<7,>=6.0\n","  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n","Collecting anyio==3.*\n","  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 7.1 MB/s \n","\u001b[?25hCollecting h11<0.13,>=0.11\n","  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n","\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.0.0->spleeter) (3.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.0->spleeter) (57.4.0)\n","Collecting numba>=0.43.0\n","  Downloading numba-0.55.2-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 44.0 MB/s \n","\u001b[?25h  Downloading numba-0.55.1-1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 42.3 MB/s \n","\u001b[?25h  Downloading numba-0.55.0-1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 39.7 MB/s \n","\u001b[?25h  Downloading numba-0.54.1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 42.2 MB/s \n","\u001b[?25h  Downloading numba-0.54.0-2-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 38.7 MB/s \n","\u001b[?25h  Downloading numba-0.53.1-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 39.3 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.1.2->spleeter) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.1.2->spleeter) (2.8.2)\n","Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->spleeter) (1.4.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->spleeter) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->spleeter) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->pooch>=1.0->librosa==0.8.0->spleeter) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->spleeter) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->spleeter) (1.24.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0->spleeter) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa==0.8.0->spleeter) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.8.0->spleeter) (2.21)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (3.4.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.35.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.3.1)\n","Collecting markdown>=2.6.8\n","  Downloading Markdown-3.4-py3-none-any.whl (93 kB)\n","\u001b[K     |████████████████████████████████| 93 kB 1.7 MB/s \n","\u001b[?25h  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 6.2 MB/s \n","\u001b[?25h  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 7.8 MB/s \n","\u001b[?25h  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (3.2.0)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.2->spleeter) (7.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fer) (3.2.2)\n","Collecting mtcnn>=0.1.1\n","  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 59.0 MB/s \n","\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from fer) (2.8.0)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from fer) (4.6.0.66)\n","Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn>=0.1.1->fer) (4.5.5.64)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (0.11.0)\n","Building wheels for collected packages: ffmpeg, librosa, wrapt\n","  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6084 sha256=a4f447cb47f058c999f6ffb4676119b5a0abdbd0f539fa48ac1e7fbaf02d48a0\n","  Stored in directory: /root/.cache/pip/wheels/64/80/6e/caa3e16deb0267c3cbfd36862058a724144e19fdb9eb03af0f\n","  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201396 sha256=22d36e06b15da1694e9dbe4a878148ddfd5880341870f0432694819d5efd6632\n","  Stored in directory: /root/.cache/pip/wheels/de/1e/aa/d91797ae7e1ce11853ee100bee9d1781ae9d750e7458c95afb\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68721 sha256=1f4458736a2f9997917059ae866aad0088b2e02f0b970aa88ea331c0cc88a4a2\n","  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n","Successfully built ffmpeg librosa wrapt\n","Installing collected packages: typing-extensions, sniffio, rfc3986, numpy, llvmlite, importlib-metadata, h11, anyio, numba, markdown, hyperframe, httpcore, hpack, grpcio, absl-py, wrapt, tensorflow-estimator, keras-nightly, httpx, h2, gast, flatbuffers, typer, tensorflow, norbert, mtcnn, librosa, ffmpeg-python, youtube-dl, xlsxwriter, webcolors, spleeter, SpeechRecognition, ffmpeg, fer\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.1.1\n","    Uninstalling typing-extensions-4.1.1:\n","      Successfully uninstalled typing-extensions-4.1.1\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.39.0\n","    Uninstalling llvmlite-0.39.0:\n","      Successfully uninstalled llvmlite-0.39.0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.12.0\n","    Uninstalling importlib-metadata-4.12.0:\n","      Successfully uninstalled importlib-metadata-4.12.0\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.56.0\n","    Uninstalling numba-0.56.0:\n","      Successfully uninstalled numba-0.56.0\n","  Attempting uninstall: markdown\n","    Found existing installation: Markdown 3.4.1\n","    Uninstalling Markdown-3.4.1:\n","      Successfully uninstalled Markdown-3.4.1\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.47.0\n","    Uninstalling grpcio-1.47.0:\n","      Successfully uninstalled grpcio-1.47.0\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.2.0\n","    Uninstalling absl-py-1.2.0:\n","      Successfully uninstalled absl-py-1.2.0\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.14.1\n","    Uninstalling wrapt-1.14.1:\n","      Successfully uninstalled wrapt-1.14.1\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 2.0\n","    Uninstalling flatbuffers-2.0:\n","      Successfully uninstalled flatbuffers-2.0\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.4.2\n","    Uninstalling typer-0.4.2:\n","      Successfully uninstalled typer-0.4.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n","    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n","      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n","  Attempting uninstall: librosa\n","    Found existing installation: librosa 0.8.1\n","    Uninstalling librosa-0.8.1:\n","      Successfully uninstalled librosa-0.8.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n","gym 0.25.1 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n","cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n","Successfully installed SpeechRecognition-3.8.1 absl-py-0.15.0 anyio-3.6.1 fer-22.4.0 ffmpeg-1.4 ffmpeg-python-0.2.0 flatbuffers-1.12 gast-0.4.0 grpcio-1.34.1 h11-0.12.0 h2-4.1.0 hpack-4.0.0 httpcore-0.13.7 httpx-0.19.0 hyperframe-6.0.1 importlib-metadata-3.10.1 keras-nightly-2.5.0.dev2021032900 librosa-0.8.0 llvmlite-0.36.0 markdown-3.3.4 mtcnn-0.1.1 norbert-0.2.1 numba-0.53.1 numpy-1.19.5 rfc3986-1.5.0 sniffio-1.2.0 spleeter-2.3.1 tensorflow-2.5.0 tensorflow-estimator-2.5.0 typer-0.3.2 typing-extensions-3.7.4.3 webcolors-1.12 wrapt-1.12.1 xlsxwriter-3.0.3 youtube-dl-2021.12.17\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","typing_extensions"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["deb https://ngrok-agent.s3.amazonaws.com buster main\n","Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n","Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:8 https://ngrok-agent.s3.amazonaws.com buster InRelease [20.3 kB]\n","Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,369 kB]\n","Get:13 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [91.1 kB]\n","Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [912 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,311 kB]\n","Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,093 kB]\n","Get:20 https://ngrok-agent.s3.amazonaws.com buster/main amd64 Packages [1,423 B]\n","Get:21 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,938 kB]\n","Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,073 kB]\n","Get:23 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,534 kB]\n","Fetched 14.6 MB in 3s (4,330 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","37 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","The following NEW packages will be installed:\n","  ngrok\n","0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n","Need to get 6,630 kB of archives.\n","After this operation, 0 B of additional disk space will be used.\n","Get:1 https://ngrok-agent.s3.amazonaws.com buster/main amd64 ngrok amd64 3.0.7 [6,630 kB]\n","Fetched 6,630 kB in 1s (7,333 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package ngrok.\n","(Reading database ... 155676 files and directories currently installed.)\n","Preparing to unpack .../archives/ngrok_3.0.7_amd64.deb ...\n","Unpacking ngrok (3.0.7) ...\n","Setting up ngrok (3.0.7) ...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (1.1.4)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask) (2.11.3)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask) (7.1.2)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask) (1.1.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask) (1.0.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask) (2.0.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: youtube_dl in /usr/local/lib/python3.7/dist-packages (2021.12.17)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting flask_ngrok\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyngrok==4.1.1\n","  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (0.16.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (6.0)\n","Building wheels for collected packages: pyngrok\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15983 sha256=3d364255f1e0875d7cfdef646d371af86ea547cf25493b626e1e3bf28a1d21c2\n","  Stored in directory: /root/.cache/pip/wheels/b1/d9/12/045a042fee3127dc40ba6f5df2798aa2df38c414bf533ca765\n","Successfully built pyngrok\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-4.1.1\n","Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.8.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from wordcloud) (3.2.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from wordcloud) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud) (3.7.4.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytrends\n","  Downloading pytrends-4.8.0.tar.gz (19 kB)\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.7/dist-packages (from pytrends) (2.23.0)\n","Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.7/dist-packages (from pytrends) (1.3.5)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pytrends) (4.9.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (2022.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25->pytrends) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0->pytrends) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0->pytrends) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0->pytrends) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0->pytrends) (3.0.4)\n","Building wheels for collected packages: pytrends\n","  Building wheel for pytrends (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytrends: filename=pytrends-4.8.0-py3-none-any.whl size=16126 sha256=fae16b5dd275430a463e26623bbded382c763e9dc885ae0eed3223cfabe72e11\n","  Stored in directory: /root/.cache/pip/wheels/07/6f/5c/8174f98dec1bfbc7d5da4092854afcbcff4b26c3d9b66b5183\n","Successfully built pytrends\n","Installing collected packages: pytrends\n","Successfully installed pytrends-4.8.0\n","Found existing installation: ffmpeg 1.4\n","Uninstalling ffmpeg-1.4:\n","  Successfully uninstalled ffmpeg-1.4\n","Found existing installation: ffmpeg-python 0.2.0\n","Uninstalling ffmpeg-python-0.2.0:\n","  Successfully uninstalled ffmpeg-python-0.2.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.7/dist-packages (3.8.1)\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n","Requirement already satisfied: spleeter in /usr/local/lib/python3.7/dist-packages (2.3.1)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy) (1.19.5)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.9.0)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.64.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n","Collecting ffmpeg-python==0.2.0\n","  Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: importlib-metadata<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spleeter) (3.10.1)\n","Requirement already satisfied: llvmlite<0.37.0,>=0.36.0 in /usr/local/lib/python3.7/dist-packages (from spleeter) (0.36.0)\n","Requirement already satisfied: tensorflow==2.5.0 in /usr/local/lib/python3.7/dist-packages (from spleeter) (2.5.0)\n","Requirement already satisfied: httpx[http2]<0.20.0,>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from spleeter) (0.19.0)\n","Requirement already satisfied: protobuf<=3.19.4 in /usr/local/lib/python3.7/dist-packages (from spleeter) (3.17.3)\n","Requirement already satisfied: pandas<2.0.0,>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from spleeter) (1.3.5)\n","Requirement already satisfied: typer<0.4.0,>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from spleeter) (0.3.2)\n","Requirement already satisfied: norbert==0.2.1 in /usr/local/lib/python3.7/dist-packages (from spleeter) (0.2.1)\n","Requirement already satisfied: librosa==0.8.0 in /usr/local/lib/python3.7/dist-packages (from spleeter) (0.8.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python==0.2.0->spleeter) (0.16.0)\n","Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (0.10.3.post1)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (0.53.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.7.3)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.6.0)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (0.4.0)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (3.0.0)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.0.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->spleeter) (1.1.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (0.15.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.6.3)\n","Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (2.8.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.1.2)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.1.0)\n","Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (2.5.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (3.3.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (0.2.0)\n","Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (2.5.0.dev2021032900)\n","Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.34.1)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (0.4.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (3.7.4.3)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.12.1)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.15.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (1.12)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (0.37.1)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->spleeter) (3.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.0->spleeter) (1.5.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (2022.6.15)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.2.0)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (2.1.0)\n","Requirement already satisfied: httpcore<0.14.0,>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (0.13.7)\n","Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.5.0)\n","Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.7/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (4.1.0)\n","Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.7/dist-packages (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (4.0.0)\n","Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.7/dist-packages (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (6.0.1)\n","Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.7/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (0.12.0)\n","Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.6.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.0.0->spleeter) (3.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.0->spleeter) (57.4.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.1.2->spleeter) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.1.2->spleeter) (2.8.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->spleeter) (2.23.0)\n","Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->spleeter) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->spleeter) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->pooch>=1.0->librosa==0.8.0->spleeter) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->spleeter) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->spleeter) (1.24.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0->spleeter) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa==0.8.0->spleeter) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.8.0->spleeter) (2.21)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (3.3.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (1.3.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->spleeter) (3.2.0)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.2->spleeter) (7.1.2)\n","Installing collected packages: ffmpeg-python\n","Successfully installed ffmpeg-python-0.2.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting python_speech_features\n","  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n","Building wheels for collected packages: python-speech-features\n","  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-speech-features: filename=python_speech_features-0.6-py3-none-any.whl size=5888 sha256=d58236c325a9b9cd8c659870a0380c999839b9cf7493001be4cfa84b52fc7c8d\n","  Stored in directory: /root/.cache/pip/wheels/b0/0e/94/28cd6afa3cd5998a63eef99fe31777acd7d758f59cf24839eb\n","Successfully built python-speech-features\n","Installing collected packages: python-speech-features\n","Successfully installed python-speech-features-0.6\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"]}],"source":["def requirements():\n","  !pip install opencv-python==4.5.5.64\n","  !pip uninstall imgaug --y\n","  !pip install imgaug==0.2.5\n","  !pip install webcolors  xlsxwriter youtube-dl SpeechRecognition moviepy ffmpeg spleeter fer\n","  #Extras\n","  !curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list &&sudo apt update &&sudo apt install ngrok \n","  !pip install flask\n","  !pip install youtube_dl\n","  !pip install flask_ngrok\n","  !pip install pyngrok==4.1.1\n","  !ngrok authtoken 27hMUYstXU9FbCK7ejYIWnDwu3g_3Bt3PL1LoHseoRkPySH5A\n","  !pip install pydub\n","\n","\n","  #audio module depedencies are present already\n","\n","  !pip install wordcloud\n","\n","  #Trends module depedencies\n","  !pip install pytrends\n","\n","  !pip3 uninstall FFmpeg ffmpeg-python --y\n","\n","  !pip install SpeechRecognition moviepy spleeter pydub\n","  #!pip3 uninstall FFmpeg ffmpeg-python\n","  !pip install python_speech_features\n","  !apt install ffmpeg\n","\n","requirements()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":502,"status":"ok","timestamp":1661775210466,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"RSYCHryWeyr2","outputId":"b38bb4d1-ed7a-4e04-c0c5-e4e6085604ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Task/object_detection_model\n"]}],"source":["cd /content/drive/MyDrive/Task/object_detection_model"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9748,"status":"ok","timestamp":1661775220853,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"om9PXWe6_lrN","outputId":"ad95a169-aee3-4a3b-d210-76acef908cfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'yolov5' already exists and is not an empty directory.\n","/content/drive/MyDrive/Task/object_detection_model/yolov5\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5  # clone\n","%cd yolov5\n","%pip install -qr requirements.txt  # install\n","import torch\n","import utils"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1661775220857,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"E4iWaaqQffP-","outputId":"20f6346f-8284-48c4-9112-762f21999914"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Task\n"]}],"source":["cd /content/drive/MyDrive/Task"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"executionInfo":{"elapsed":5395,"status":"error","timestamp":1661775226240,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"vkRYO378I7tK","outputId":"491333fe-1b28-4e74-9f41-345e9e6fd70c"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-6c8a485fec2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspeech_recognition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplit_on_silence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/editor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Checks to see if the user has set a place for their own version of ffmpeg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FFMPEG_BINARY'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ffmpeg-imageio'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ffmpeg-imageio'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffmpeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Clips\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/plugins/ffmpeg.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(directory, force_download)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     raise RuntimeError(\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;34m\"imageio.ffmpeg.download() has been deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;34m\"Use 'pip install imageio-ffmpeg' instead.'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     )\n","\u001b[0;31mRuntimeError\u001b[0m: imageio.ffmpeg.download() has been deprecated. Use 'pip install imageio-ffmpeg' instead.'"]}],"source":["import urllib.request\n","import re\n","import cv2\n","from PIL import Image\n","import os\n","import glob\n","import pandas as pd\n","import youtube_dl\n","from glob import glob\n","import numpy as np\n","import torch\n","import math\n","import webcolors\n","from fer import Video, FER\n","from scipy.spatial import KDTree\n","from sklearn.cluster import KMeans\n","from collections import Counter\n","import urllib.request\n","import shutil\n","import time\n","import matplotlib\n","from google.colab.patches import cv2_imshow\n","import xlsxwriter\n","import xlwt\n","from xlwt.Workbook import *\n","from pandas import ExcelWriter\n","from IPython.display import HTML\n","from base64 import b64encode\n","from IPython.display import Audio\n","import speech_recognition as sr \n","#import moviepy.editor as mp\n","from pydub import AudioSegment\n","from pydub.silence import split_on_silence\n","from os import path\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud, STOPWORDS\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud, STOPWORDS\n","import numpy as np\n","import os\n","import pickle\n","import random\n","import pandas as pd\n","import sklearn\n","import scipy.io.wavfile as wav\n","from os import path\n","from pydub import AudioSegment\n","from python_speech_features import mfcc\n","from sklearn.metrics import classification_report\n","from collections import defaultdict\n","#import keras\n","\n","\n","#audio module depedencies are already present\n","import ffmpeg\n","\n","\n","#Trends                        \n","from pytrends.request import TrendReq\n","from google.colab import files\n","\n","\n","###extra\n","from flask import Flask,redirect,url_for,render_template,request\n","from flask_ngrok import run_with_ngrok\n","from glob import glob\n","from time import sleep\n","from threading import Thread"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7835,"status":"ok","timestamp":1661343735343,"user":{"displayName":"advertflair usa","userId":"06554812444216316186"},"user_tz":-330},"id":"nluh5L6BzWAE","outputId":"71e3a615-017a-42f6-a0d1-8acc9e6a2a3d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting imageio-ffmpeg\n","  Downloading imageio_ffmpeg-0.4.7-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[K     |████████████████████████████████| 26.9 MB 60.6 MB/s \n","\u001b[?25hInstalling collected packages: imageio-ffmpeg\n","Successfully installed imageio-ffmpeg-0.4.7\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MoD0iPWLOmyd"},"outputs":[],"source":["!ngrok authtoken 27hMUYstXU9FbCK7ejYIWnDwu3g_3Bt3PL1LoHseoRkPySH5A"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mwBloFPq-RLO"},"outputs":[],"source":["def ana():\n","\n","      \n","      #//1\n","      #color names\n","      sleep(1)\n","      hexcodes = []\n","      colornames = []\n","\n","      for cname, hex in matplotlib.colors.cnames.items():\n","          hexcodes.append(hex)\n","          colornames.append(cname)\n","          #print(hex,cname)\n","\n","      zipbObj = zip(hexcodes, colornames)\n","      new_hex_colors = dict(zipbObj)\n","\n","      def RGB2HEX(color):\n","          return \"#{:02x}{:02x}{:02x}\".format(int(color[0]), int(color[1]), int(color[2]))\n","      #//2\n","      def closer_color(image):\n","          hexnames = new_hex_colors\n","          names = []\n","          positions = []\n","          \n","          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","          dst = cv2.fastNlMeansDenoisingColored(image,None,10,10,7,21)\n","          modified_image = cv2.resize(dst, (600, 400), interpolation = cv2.INTER_AREA)\n","          \n","          input_image = image.reshape(image.shape[0]*image.shape[1], 3)\n","          clf = KMeans(n_clusters = 1)\n","          labels = clf.fit_predict(input_image)\n","          counts = Counter(labels)\n","\n","          center_colors = clf.cluster_centers_\n","          \n","          ordered_colors = [center_colors[i] for i in counts.keys()]\n","          hex_colors = [RGB2HEX(ordered_colors[i]) for i in counts.keys()]\n","          rgb_colors = [ordered_colors[i] for i in counts.keys()]\n","          \n","          for i in hexnames:\n","              names.append(hexnames[i])\n","              positions.append(webcolors.hex_to_rgb(i))\n","              \n","          spacedb = KDTree(positions)\n","\n","          x = rgb_colors\n","          \n","          x[0] = [int(i) for i in x[0]]\n","          dist, index = spacedb.query(x[0])\n","          \n","          return names[index]\n","      #//3\n","      #loading object detection model\n","      \n","      \n","      \n","      def object_detection():\n","        model = torch.hub.load(\"/content/drive/MyDrive/Task/object_detection_model/yolov5\", 'yolov5s', source = 'local') \n","        return model\n","      \n","      #//4\n","      object_model = object_detection()\n","\n","      #//5\n","      def highlightFace(net, frame, conf_threshold=0.7):\n","          frameOpencvDnn=frame.copy()\n","          frameHeight=frameOpencvDnn.shape[0]\n","          frameWidth=frameOpencvDnn.shape[1]\n","          blob=cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n","\n","          net.setInput(blob)\n","          detections=net.forward()\n","          faceBoxes=[]\n","          for i in range(detections.shape[2]):\n","              confidence=detections[0,0,i,2]\n","              if confidence>conf_threshold:\n","                  x1=int(detections[0,0,i,3]*frameWidth)\n","                  y1=int(detections[0,0,i,4]*frameHeight)\n","                  x2=int(detections[0,0,i,5]*frameWidth)\n","                  y2=int(detections[0,0,i,6]*frameHeight)\n","                  faceBoxes.append([x1,y1,x2,y2])\n","                  cv2.rectangle(frameOpencvDnn, (x1,y1), (x2,y2), (0,255,0), int(round(frameHeight/150)), 8)\n","          return frameOpencvDnn,faceBoxes\n","\n","      faceProto=\"gender_age_detection_model/opencv_face_detector.pbtxt\"\n","      faceModel=\"gender_age_detection_model/opencv_face_detector_uint8.pb\"\n","\n","      ageProto=\"gender_age_detection_model/age_deploy.prototxt\"\n","      ageModel=\"gender_age_detection_model/age_net.caffemodel\"\n","\n","      genderProto=\"gender_age_detection_model/gender_deploy.prototxt\"\n","      genderModel=\"gender_age_detection_model/gender_net.caffemodel\"\n","\n","      MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746)\n","      ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n","      genderList=['Male','Female']\n","\n","      faceNet=cv2.dnn.readNet(faceModel,faceProto)\n","      ageNet=cv2.dnn.readNet(ageModel,ageProto)\n","      genderNet=cv2.dnn.readNet(genderModel,genderProto)\n","\n","      padding=20\n","\n","\n","      def age_gender_detector(temp):\n","        obj_frame_no= []\n","        object_name = []\n","        color_name = []\n","        gender_name =[]\n","        age_group = []\n","        gender_frame_no = []\n","        fn = 0\n","        return_data1 = []\n","        return_data2 = []\n","        return_data3 = []\n","        for num in range(len(temp)):\n","          im = temp[num]\n","          frame = cv2.imread(im)\n","          print(f\"image number:{im}\")\n","          fn += 1\n","          \n","\n","          t=time.time()\n","          resultImg,faceBoxes=highlightFace(faceNet,frame)\n","          \n","          \n","          \n","          if not faceBoxes:\n","            gender_name.append(\"NaN\")\n","            age_group.append(\"NaN\")\n","            gender_frame_no.append(fn)\n","            print(\"No face detected\") \n","          \n","              \n","          for faceBox in faceBoxes:\n","              print(faceBox)\n","              face=frame[max(0,faceBox[1]-padding):\n","                        min(faceBox[3]+padding,frame.shape[0]-1),max(0,faceBox[0]-padding)\n","                        :min(faceBox[2]+padding, frame.shape[1]-1)]\n","              a = max(0,faceBox[1]-padding)\n","              b = min(faceBox[3]+padding,frame.shape[0]-1)\n","              c = max(0,faceBox[0]-padding)\n","              d = min(faceBox[2]+padding, frame.shape[1]-1)\n","              print(\"CHECKING THE FACE FRAME\", len(face), \n","                    \"\\n\", max(0,faceBox[1]-padding), \n","                    \"\\t\", min(faceBox[3]+padding,frame.shape[0]-1), \n","                    \"\\n\", max(0,faceBox[0]-padding), \n","                    \"\\t\", min(faceBox[2]+padding, frame.shape[1]-1))\n","              if(len(face) != 0) and (a != b and c != d): \n","                print(a,c, \"\\n\")\n","                print(b,d)\n","                if(a>b and c>d) or (a<b and c<d):\n","                  blob=cv2.dnn.blobFromImage(face, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False)\n","\n","              #running gender detection model\n","              genderNet.setInput(blob)\n","              genderPreds=genderNet.forward()\n","              gender=genderList[genderPreds[0].argmax()]\n","              #print(\"Gender Type\", type(gender))\n","              #running age detection model\n","              ageNet.setInput(blob)\n","              agePreds=ageNet.forward()\n","              age=ageList[agePreds[0].argmax()]\n","              gender_name.append(gender)\n","              age_group.append(age)\n","              gender_frame_no.append(fn)\n","              color_name.append(closer_color(frame))\n","              results = object_model(frame)\n","              objects = results.pandas().xyxy[0]\n","              for i in objects[\"name\"]:\n","                obj_frame_no.append(fn)\n","                object_name.append(i)\n","              label = \"{},{}\".format(gender, age)\n","              cv2.putText(resultImg, f'{gender}, {age}', (faceBox[0], faceBox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2, cv2.LINE_AA)\n","              #cv2.imshow(\"Age Gender Demo\", resultImg)\n","              #print(\"Gender\", gender_name)\n","              \n","          return_data1 = pd.DataFrame({'gender_frame':gender_frame_no,'gender_name': gender_name,'age_group': age_group})#[gender_frame_no, gender_name, age_group]\n","          return_data2 = pd.DataFrame({'object_name': object_name})\n","          return_data3 = pd.DataFrame({'color_name':color_name})\n","        # return resultImg\n","        #name = \"DataFrame.xlsx\"\n","        #return_data1.to_excel(name)\n","        return return_data1,return_data2,return_data3\n","\n","      #//6\n","      folders_path = \"/content/drive/MyDrive/Task/save/\"\n","      video_frames_dir = []\n","      vidframe_list1 =[]\n","      vidframe_list2 =[]\n","      vidframe_list3 =[]\n","      vidframe_list4 =[]\n","      vidframe_list5 = []\n","\n","      for root, subdirectories, files in os.walk(folders_path):\n","          for subdirectory in subdirectories:\n","              video_frames_dir.append(os.path.join(root, subdirectory))\n","\n","      #//7\n","      for x in os.listdir(video_frames_dir[0]):\n","          vidframe_list1.append(os.path.join(video_frames_dir[0],x)) \n","\n","      for x in os.listdir(video_frames_dir[1]):\n","          vidframe_list2.append(os.path.join(video_frames_dir[1],x))  \n","\n","      for x in os.listdir(video_frames_dir[2]):\n","          vidframe_list3.append(os.path.join(video_frames_dir[2],x)) \n","\n","      for x in os.listdir(video_frames_dir[3]):\n","         vidframe_list4.append(os.path.join(video_frames_dir[3],x))\n","\n","      for x in os.listdir(video_frames_dir[4]):\n","         vidframe_list5.append(os.path.join(video_frames_dir[4],x)) \n","\n","      #//8\n","      all_list = [vidframe_list1,vidframe_list2,vidframe_list3,vidframe_list4,vidframe_list5]#\n","      #//9\n","      for j in range(0, len(all_list)):\n","        temp = all_list[j]\n","        print(\"Folder Number: \", j+1)\n","        gender_details,object_details,color_details = age_gender_detector(temp)\n","        print(\"done\")\n","        excel_name = \"Folder_\" + str(j+1) + \".xlsx\"\n","        excelfile = pd.ExcelWriter(excel_name)\n","        gender_details.to_excel(excelfile, \"Gender\")\n","        object_details.to_excel(excelfile, \"Object\")\n","        color_details.to_excel(excelfile, \"Color\")\n","        excelfile.save()\n","        print(\"SAVED EXCEL\")\n","     \n","      \n","      print(\"Fin ana>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n","      global ana_status\n","      ana_status=ana_status+1\n","      return\n","\n","\n","def face():\n","      video_files = glob(r\"/content/drive/MyDrive/Task/*.mp4\")\n","      len(video_files)\n","\n","      vidf=video_files[1:]\n","      vidf.append(video_files[0])\n","\n","      # from mtcnn import MTCNN\n","      face_detector = FER(mtcnn=True)\n","      for vid in range(0,len(video_files)):\n","        temp1 = vidf[vid]\n","        input_video = Video(temp1)\n","        processing_data = input_video.analyze(face_detector, display=False)\n","        vid_df = input_video.to_pandas(processing_data)\n","        vid_df = input_video.get_first_face(vid_df)\n","        vid_df = input_video.get_emotions(vid_df)\n","        angry = sum(vid_df.angry)\n","        disgust = sum(vid_df.disgust)\n","        fear = sum(vid_df.fear)\n","        happy = sum(vid_df.happy)\n","        sad = sum(vid_df.sad)\n","        surprise = sum(vid_df.surprise)\n","        neutral = sum(vid_df.neutral)\n","        emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n","        emotions_values = [angry, disgust, fear, happy, sad, surprise, neutral]\n","        score_comparisons = pd.DataFrame(emotions, columns = ['Human Emotions'])\n","        score_comparisons['Emotion Value'] = [round(x,2) for x in emotions_values]\n","        score_comparisons.sort_values(by = ['Emotion Value'],inplace = True, ascending = False)\n","        print(score_comparisons)\n","        excel_name = \"/content/drive/MyDrive/Task/Emotions_Folder_\" + str(vid+1) + \".xlsx\"\n","        excelfile = pd.ExcelWriter(excel_name)\n","        score_comparisons.to_excel(excelfile, \"Emotions\")\n","        excelfile.save()\n","\n","      global ana_status\n","      ana_status=ana_status+1\n","      return\n","\n","\n","\n","\n","def create_audio():\n","    \n","        #for uploaded video\n","    clip1 = mp.VideoFileClip(r\"/content/drive/MyDrive/Task/video0.mp4\") \n","    \n","    clip1.audio.write_audiofile(r\"/content/drive/MyDrive/Task/A0.mp3\")\n","    #for video1\n","    clip1 = mp.VideoFileClip(r\"/content/drive/MyDrive/Task/video1.mp4\") \n","    \n","    clip1.audio.write_audiofile(r\"/content/drive/MyDrive/Task/A1.mp3\")\n","    #for video2\n","    clip1 = mp.VideoFileClip(r\"/content/drive/MyDrive/Task/video2.mp4\") \n","    \n","    clip1.audio.write_audiofile(r\"/content/drive/MyDrive/Task/A2.mp3\")\n","    #for video3\n","    clip1 = mp.VideoFileClip(r\"/content/drive/MyDrive/Task/video3.mp4\") \n","    \n","    clip1.audio.write_audiofile(r\"/content/drive/MyDrive/Task/A3.mp3\")\n","    #for video4\n","    clip1 = mp.VideoFileClip(r\"/content/drive/MyDrive/Task/video4.mp4\") \n","    \n","    clip1.audio.write_audiofile(r\"/content/drive/MyDrive/Task/A4.mp3\")\n","\n","    !spleeter separate -o /content/drive/MyDrive/Task/audioout/ /content/drive/MyDrive/Task/A0.mp3 #uploaded video\n","    !spleeter separate -o /content/drive/MyDrive/Task/audioout/ /content/drive/MyDrive/Task/A1.mp3 #for video1\n","    !spleeter separate -o /content/drive/MyDrive/Task/audioout/ /content/drive/MyDrive/Task/A2.mp3 #for video2\n","    !spleeter separate -o /content/drive/MyDrive/Task/audioout/ /content/drive/MyDrive/Task/A3.mp3 #for video3\n","    !spleeter separate -o /content/drive/MyDrive/Task/audioout/ /content/drive/MyDrive/Task/A4.mp3 #for video4\n","    print(\"Done create audio>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n","\n","def speech_to_txt():\n","    import speech_recognition as sr \n","    import os \n","    import shutil\n","    from pydub import AudioSegment\n","    from pydub.silence import split_on_silence\n","\n","    # create a speech recognition object\n","    r = sr.Recognizer()\n","    paths = [\"/content/drive/MyDrive/Task/audioout/A0/vocals.wav\",\"/content/drive/MyDrive/Task/audioout/A1/vocals.wav\",\"/content/drive/MyDrive/Task/audioout/A2/vocals.wav\",\"/content/drive/MyDrive/Task/audioout/A3/vocals.wav\",\"/content/drive/MyDrive/Task/audioout/A4/vocals.wav\"]#\n","    txt=['A0','A1','A2','A3','A4']#\n","\n","    # a function that splits the audio file into chunks\n","    # and applies speech recognition\n","    def get_large_audio_transcription(path):\n","        \"\"\"\n","        Splitting the large audio file into chunks\n","        and apply speech recognition on each of these chunks\n","        \"\"\"\n","        count=0\n","        # open the audio file using pydub\n","        sound = AudioSegment.from_wav(path)  \n","        # split audio sound where silence is 700 miliseconds or more and get chunks\n","        chunks = split_on_silence(sound,\n","            # experiment with this value for your target audio file\n","            min_silence_len = 500,\n","            # adjust this per requirement\n","            silence_thresh = sound.dBFS-16,\n","            # keep the silence for 1 second, adjustable as well\n","            keep_silence=500,\n","        )\n","        folder_name = \"/content/drive/MyDrive/Task/audioout/\"+txt[count]+\"/audio-chunks\"\n","        count+=1\n","        # create a directory to store the audio chunks\n","        if not os.path.isdir(folder_name):\n","            os.mkdir(folder_name)\n","        whole_text = \"\"\n","        # process each chunk \n","        for i, audio_chunk in enumerate(chunks, start=1):\n","            # export audio chunk and save it in\n","            # the `folder_name` directory.\n","            chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n","            audio_chunk.export(chunk_filename, format=\"wav\")\n","            # recognize the chunk\n","            with sr.AudioFile(chunk_filename) as source:\n","                audio_listened = r.record(source)\n","                # try converting it to text\n","                try:\n","                    text = r.recognize_google(audio_listened)\n","                except sr.UnknownValueError as e:\n","                    print(\"Error:\", str(e))\n","                else:\n","                    text = f\"{text.capitalize()}. \"\n","                    print(chunk_filename, \":\", text)\n","                    whole_text += text\n","        # return the text for all chunks detected\n","        return whole_text\n","\n","    #print(\"\\nFull text:\", get_large_audio_transcription(path))\n","    if os.path.exists('/content/drive/MyDrive/Task/Visualization'):\n","        shutil.rmtree('/content/drive/MyDrive/Task/Visualization')\n","    os.mkdir('/content/drive/MyDrive/Task/Visualization')\n","    counter=0\n","    for path in paths:\n","        result1 = (get_large_audio_transcription(path))\n","        if len(result1) != 0:\n","            with open('/content/drive/MyDrive/Task/Visualization/'+txt[counter]+'.txt',mode ='w') as file: \n","                #file.write(\":\") \n","                #file.write(\"\\n\") \n","                file.write(result1) \n","                print(\"ready!\")\n","        counter+=1\n","    print(\"Done speech to text>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n","    global ana_status\n","    ana_status=ana_status+1\n","\n","    \n","def random_color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):\n","    h = int(360.0 * 45.0 / 255.0)\n","    s = int(100.0 * 255.0 / 255.0)\n","    l = int(100.0 * float(random_state.randint(60, 120)) / 255.0)\n","\n","    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n","\n","def word_cloud():\n","    text_files =[]\n","    all_text = \"/content/drive/MyDrive/Task/Visualization\"\n","    os.chdir(all_text)\n","\n","    # iterate through all file\n","    for file in os.listdir():\n","        # Check whether file is in text format or not\n","        if file.endswith(\".txt\"):\n","            file_path = f\"{all_text}/{file}\"\n","            #print(file_path)\n","            text_files.append(file_path)\n","\n","    \n","    print('len(text_files)')\n","    print(len(text_files))\n","    for txt in range(0,len(text_files)):\n","        temp1 = text_files[txt]\n","        print(temp1)\n","        file_content=open(temp1).read()\n","        #file_content= read_text_file(temp1)\n","        print(file_content)\n","        wordcloud = WordCloud(font_path = r'/content/drive/MyDrive/Task/verdana/verdana/verdana.ttf',\n","                                    stopwords = STOPWORDS,\n","                                    background_color = 'green',\n","                                    width = 1200,\n","                                    height = 1000,\n","                                    color_func = random_color_func).generate(file_content)\n","\n","        plt.imshow(wordcloud)\n","        plt.axis('off')\n","        plt.savefig(path.join(all_text,\"V{0}.png\".format(txt)))\n","        plt.show()\n","    print(\"done Word cloud>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n","    global ana_status\n","    ana_status=ana_status+1\n","    return\n","\n","\n","#trends\n","def trends(location,product_name):\n","    print('trends')\n","    print(location)\n","    print(product_name)\n","    pytrends = TrendReq(hl='en-US', tz=360)\n","    #user input\n","    Location = str(location).lower().replace(\" \",\"_\")\n","\n","    #trends\n","\n","    pytrend = TrendReq()\n","    # Get realtime Google Trends data\n","    df = pytrend.trending_searches(pn= Location)\n","    print(\"Top Trends in the country\")\n","    print(df[:5])\n","\n","\n","    #save to csv\n","    #allqueries.to_csv('allqueries.csv')\n","\n","    #download from collab\n","    #files.download(\"allqueries.csv\")\n","\n","    #provide your search terms\n","    Input_keyword = product_name.split('+')[0]\n","    kw_list=[Input_keyword]\n","\n","    pytrend.build_payload(kw_list=kw_list, geo= 'US')\n","\n","\n","    #get related queries\n","    related_queries = pytrend.related_queries()\n","    related_queries.values()\n","\n","    #build lists dataframes\n","\n","    top = list(related_queries.values())[0]['top']\n","    rising = list(related_queries.values())[0]['rising']\n","\n","    #convert lists to dataframes\n","\n","    dftop = pd.DataFrame(top)\n","    dfrising = pd.DataFrame(rising)\n","\n","    #join two data frames\n","    joindfs = [dftop, dfrising]\n","    allqueries = pd.concat(joindfs, axis=1)\n","\n","    #function to change duplicates\n","\n","    cols=pd.Series(allqueries.columns)\n","    for dup in allqueries.columns[allqueries.columns.duplicated(keep=False)]: \n","        cols[allqueries.columns.get_loc(dup)] = ([dup + '.' + str(d_idx) \n","                                        if d_idx != 0 \n","                                        else dup \n","                                        for d_idx in range(allqueries.columns.get_loc(dup).sum())]\n","                                        )\n","    allqueries.columns=cols\n","\n","    #rename to proper names\n","\n","    allqueries.rename({'query': 'top query', 'value': 'top query value', 'query.1': 'related query', 'value.1': 'related query value'}, axis=1, inplace=True) \n","\n","    #check your dataset\n","    print(\"Product related Queries \")\n","    print(allqueries['related query'][:10])\n","    print(type(df[:5]))\n","    s=allqueries['related query'][:10]\n","    s=s.to_frame()#.reset_index()\n","    #s = s.rename(columns= {0: 'list'})\n","    #s.index.name = 'index'\n","\n","    table1=[df[:5].to_html(classes='data', header=\"true\")]\n","    table2=[s.to_html(classes='data', header=\"true\")]\n","    \n","    global ana_status\n","    ana_status=ana_status+1\n","    return table1,table2\n","\n","\n","#create folder visualization\n","if os.path.exists('/content/drive/MyDrive/Task/Visualization'):\n","        shutil.rmtree('/content/drive/MyDrive/Task/Visualization')\n","os.mkdir('/content/drive/MyDrive/Task/Visualization')\n","\n","\n","\n","def obj_vis():\n","    \n","\n","    obj_df1 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_1.xlsx', \"Object\")\n","    obj_df2 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_2.xlsx', \"Object\")\n","    obj_df3 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_3.xlsx', \"Object\")\n","    obj_df4 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_4.xlsx', \"Object\")\n","    obj_df5 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_5.xlsx', \"Object\")\n","\n","    #genage_df1 = pd.read_excel(r'/content/drive/MyDrive/Recommendation/Folder_1.xlsx', \"Gender\")\n","    #sent_df1 = pd.read_excel(r'/content/drive/MyDrive/Recommendation/Emotions_Folder_1.xlsx', \"Sentiment\")\n","    #text_df1 = pd.read_excel(r'/content/drive/MyDrive/Recommendation/Folder_1.xlsx', \"Color\")\n","    plt.figure();\n","    ax = obj_df1['object_name'].value_counts().plot(kind='bar',\n","                                        figsize=(12,5),\n","                                        title=\"Video 1_Number of Unique Objects\", rot='0')\n","    ax.set_xlabel(\"Objects\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V1_obj.png')\n","\n","    ax = obj_df2['object_name'].value_counts().plot(kind='bar',\n","                                        figsize=(12,5),\n","                                        title=\"Video 2_Number of Unique Objects\", rot='0')\n","    ax.set_xlabel(\"Objects\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V2_obj.png')\n","\n","    ax = obj_df3['object_name'].value_counts().plot(kind='bar',stacked = True,\n","                                        figsize=(12,5),\n","                                        title=\"Video 3_Number of Unique Objects\", rot='0')\n","    ax.set_xlabel(\"Objects\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V3_obj.png')\n","\n","    ax = obj_df4['object_name'].value_counts().plot(kind='bar',\n","                                        figsize=(12,5),\n","                                        title=\"Video 4_Number of Unique Objects\", rot='0')\n","    ax.set_xlabel(\"Objects\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V4_obj.png')\n","\n","    ax = obj_df5['object_name'].value_counts().plot(kind='bar',\n","                                        figsize=(12,5),\n","                                        title=\"Video 5_Number of Unique Objects\", rot='0')\n","    ax.set_xlabel(\"Objects\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V5_obj.png')\n","\n","    obj1 = obj_df1['object_name'].value_counts()\n","    obj2 = obj_df2['object_name'].value_counts()\n","    obj3 = obj_df3['object_name'].value_counts()\n","    obj4 = obj_df4['object_name'].value_counts()\n","    obj5 = obj_df5['object_name'].value_counts()\n","\n","    v1 = len(obj_df1['object_name'])\n","    v2 = len(obj_df2['object_name'])\n","    v3 = len(obj_df3['object_name'])\n","    v4 = len(obj_df4['object_name'])\n","    v5 = len(obj_df5['object_name'])\n","\n","    df1 = [{v1,v2,v3,v4,v5}]\n","    df1 ={'videos':['v1','v2','v3','v4','v5'], 'objc':[v1,v2,v3,v4,v5]}\n","    df2 = pd.DataFrame(df1)\n","    df3 = df2.objc\n","    print(df2)\n","    global obj_msg\n","    global obj_msg1,obj_msg2,obj_msg3,obj_msg4\n","    #obj message for video 1 and 4\n","    if df3[1] >= df3[0] :\n","        obj_msg1=(f\"Video 2 has Higher Number of Objects on Count compared with Benchmark video : \\nobjects : Video 2 object count:{v2} Benchmark video object count:{v1}\")\n","        obj_msg.append(obj_msg1)\n","    else:\n","        obj_msg1=(f\"Benchmark video has Higher Number of Objects on Count compared with Video 2 : \\nobjects : Video 2 object count:{v2} Benchmark video object count:{v1}\")\n","        obj_msg.append(obj_msg1)\n","    #obj message for video 2 and 4\n","    if df3[2] >= df3[0] :\n","        obj_msg2=(f\"Video 3 has Higher Number of Objects on Count compared with Benchmark video:\\nobjects : Video 3 object count:{v3}  Benchmark video object count:{v1}\")\n","        obj_msg.append(obj_msg2)\n","    else:\n","        obj_msg2=(f\"Benchmark video has Higher Number of Objects on Count compared with Video 3 :\\nobjects : Video 3 object count:{v3}  Benchmark video object count:{v1}\")\n","        obj_msg.append(obj_msg2)\n","    #obj message for video 3 and 4\n","    if df3[3] >= df3[0] :\n","        obj_msg3=(f\"Video 4 has Higher Number of Objects on Count compared with Benchmark video :\\nobjects : Video 4 object count:{v4} Benchmark video object count:{v1}\")\n","        obj_msg.append(obj_msg3)\n","    else:\n","        obj_msg3 = (f\"Benchmark video has Higher Number of Objects on Count compared with Video 4 :\\nobjects : Video 4 object count:{v4} Benchmark video object count:{v1}\")\n","        obj_msg.append(obj_msg3)\n","    if df3[4] >= df3[0] :\n","        obj_msg4=(f\"Video 5 has Higher Number of Objects on Count compared with Benchmark video :\\nobjects : Video 5 object count:{v5} Benchmark video object count:{v1}\")\n","        obj_msg.append(obj_msg4)\n","    else:\n","        obj_msg4 = (f\"Benchmark video has Higher Number of Objects on Count compared with Video 5 :\\nobjects : Video 5 object count:{v5} Benchmark video object count:{v1}\")\n","        obj_msg.append(obj_msg4)\n","\n","\n","\n","    global ana_status\n","    ana_status=ana_status+1\n","\n","\n","\n","def gender():\n","  gen_df1 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_1.xlsx', \"Gender\")\n","  gen_df2 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_2.xlsx', \"Gender\")\n","  gen_df3 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_3.xlsx', \"Gender\")\n","  gen_df4 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_4.xlsx', \"Gender\")\n","  gen_df5 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_5.xlsx', \"Gender\")\n","\n","  #genage_df1 = pd.read_excel(r'/content/drive/MyDrive/Recommendation/Folder_1.xlsx', \"Gender\")\n","  #sent_df1 = pd.read_excel(r'/content/drive/MyDrive/Recommendation/Emotions_Folder_1.xlsx', \"Sentiment\")\n","  #text_df1 = pd.read_excel(r'/content/drive/MyDrive/Recommendation/Folder_1.xlsx', \"Color\")\n","  gen_df1 = gen_df1.dropna()\n","  gen_df2 = gen_df2.dropna()\n","  gen_df3 = gen_df3.dropna()\n","  gen_df4 = gen_df4.dropna()\n","  gen_df5 = gen_df5.dropna()\n","\n","  v1_g_m = sum(gen_df1.gender_name == 'Male')\n","  v1_g_f = sum(gen_df1.gender_name == 'Female')\n","  v2_g_m = sum(gen_df2.gender_name == 'Male')\n","  v2_g_f = sum(gen_df2.gender_name == 'Female')\n","  v3_g_m = sum(gen_df3.gender_name == 'Male')\n","  v3_g_f = sum(gen_df3.gender_name == 'Female')\n","  v4_g_m = sum(gen_df4.gender_name == 'Male')\n","  v4_g_f = sum(gen_df4.gender_name == 'Female')\n","  v5_g_m = sum(gen_df5.gender_name == 'Male')\n","  v5_g_f = sum(gen_df5.gender_name == 'Female')\n","  plt.figure();\n","  ax = gen_df1['gender_name'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 1_ Gener Classification\", rot='0')\n","  ax.set_xlabel(\"Gender\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V1_gen.png')\n","\n","  ax = gen_df1['age_group'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 1_Age Distribution\", rot='0')\n","  ax.set_xlabel(\"Ages\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V1_Age.png')\n","\n","  bb3 = pd.pivot_table(gen_df1, index=['age_group'], columns=['gender_name'], values=['gender_frame'], aggfunc='count')\n","  bb3\n","  plt.figure(); \n","  bb3.plot.bar(title='Fig.No. 4 : STACKED BAR CHART', stacked=True); \n","  plt.xlabel('Age Group'); plt.ylabel('Gender') \n","\n","  plt.figure(); \n","  bb3.plot.bar(title='Fig.No. 4 : STACKED BAR CHART', stacked=True); \n","  plt.xlabel('Age Group'); plt.ylabel('Gender') \n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/stacked_bar.png')\n","\n","  ax = gen_df2['gender_name'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 2_Gender Classification\", rot='0')\n","  ax.set_xlabel(\"Gender\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V2_gen.png')\n","\n","  ax = gen_df2['age_group'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 2_Age Distribution\", rot='0')\n","  ax.set_xlabel(\"Age\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V2_age.png')\n","\n","  ax = gen_df3['gender_name'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 3_Gender Classification\", rot='0')\n","  ax.set_xlabel(\"Gender\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V3_gen.png')\n","\n","  ax = gen_df3['age_group'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 3_Age Distribution\", rot='0')\n","  ax.set_xlabel(\"Age\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V3_age.png')  \n","\n","  ax = gen_df4['gender_name'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 4_Gender Classification\", rot='0')\n","  ax.set_xlabel(\"Gender\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V4_gen.png')  \n","\n","  ax = gen_df4['age_group'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 4_Age Distribution\", rot='0')\n","  ax.set_xlabel(\"Age\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V4_age.png')\n","\n","  ax = gen_df5['gender_name'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 5_Gender Classification\", rot='0')\n","  ax.set_xlabel(\"Gender\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V5_gen.png')\n","\n","  ax = gen_df5['age_group'].value_counts().plot(kind='bar',\n","                                    figsize=(6,4),\n","                                    title=\"Video 5_Age Distribution\", rot='0')\n","  ax.set_xlabel(\"Age\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/V5_age.png')\n","\n","\n","  v1_a = gen_df1['age_group'].value_counts()\n","  v2_a = gen_df2['age_group'].value_counts()\n","  v3_a = gen_df3['age_group'].value_counts()\n","  v4_a = gen_df4['age_group'].value_counts()\n","  v5_a = gen_df5['age_group'].value_counts()\n","\n","  global gender_msg\n","  if v2_g_m >= v1_g_m :\n","    s1=(f\"Video 2 has Higher Number of Male on Count compared with Benchmark video : \\n Gender : Male count in video 2:{v2_g_m}  Male count in benchmark video :{v1_g_m} \")\n","    #ss1=(f'Gender : V2_Male:{v2_g_m}  V1_Male:{v1_g_m} '  )\n","  else:\n","      s1=print(f\"Benchmark video has Higher Number of Male on Count compared with Video 2 : Male count in video 2:{v2_g_m}   Male count in benchmark video:{v1_g_m}  \"   )\n","      #ss1=print(f': V2_Male:{v2_g_m}  V1_Male:{v1_g_m} '  )\n","\n","  if v2_g_f >= v1_g_f :\n","    s2=(f\"Video 2 has Higher Number of Female on Count compared with Benchmark video : Gender : Female count in video 2:{v2_g_f}  Female count in benchmark video:{v1_g_f} \"   )\n","    #ss2=(f'Gender : V2_Female:{v2_g_f}  V1_Female:{v1_g_f} '  )\n","  else:\n","      s2=(f\"Benchmark video has Higher Number of Female on Count compared with Video 2 : Gender : Female count in video 2:{v2_g_f}  Female count in benchmark video:{v1_g_f}  \"   )\n","      #ss2=(f'Gender : V2_Female:{v2_g_f}  V1_Female:{v1_g_f} '  )\n","  \n","  if v3_g_m >= v1_g_m :\n","    s3=(f\"Video 3 has Higher Number of Male on Count compared with Benchmark video : Gender :  Male count in video 3:{v3_g_m}  Male count in benchmark video:{v1_g_m} \"   )\n","    #ss3=(f'Gender : V3_Male:{v3_g_m}  V1_Male:{v1_g_m} '  )\n","  else:\n","      s3=(f\"Benchmark video has Higher Number of Male on Count compared with Video 3 : Gender :  Male count in video 3:{v3_g_m}  Male count in benchmark video:{v1_g_m} \"   )\n","      #ss3=(f'Gender : V3_Male:{v3_g_m}  V1_Male:{v1_g_m} '  )\n","  \n","  if v3_g_f >= v1_g_f :\n","    s4=(f\"Video 3 has Higher Number of Female on Count compared with Benchmark video : Gender : Female count in video 3:{v3_g_f}  Female count in benchmark video:{v1_g_f} \"   )\n","    #ss4=(f'Gender : V3_Female:{v3_g_f}  V1_Female:{v1_g_f} '  )\n","  else:\n","      s4=(f\"Benchmark video has Higher Number of Female on Count compared with Video 3 : Gender : Female count in video 3:{v3_g_f}  Female count in benchmark video:{v1_g_f} \"   )\n","      #ss4=(f'Gender : V3_Female:{v3_g_f}  V1_Female:{v1_g_f} '  )\n","  \n","  if v4_g_m >= v1_g_m :\n","    s5=(f\"Video 4 has Higher Number of Male on Count compared with Benchmark video : Gender :  Male count in video 4:{v4_g_m}  Male count in benchmark video:{v1_g_m} \"   )\n","    #ss5=(f'Gender : V4_Male:{v4_g_m}  V1_Male:{v1_g_m} '  )\n","  else:\n","      s5=(f\"Benchmark video has Higher Number of Male on Count compared with Video 4 : Gender :  Male count in video 4:{v4_g_m}  Male count in benchmark video:{v1_g_m}\"   )\n","      #ss5=(f'Gender : V4_Male:{v4_g_m}  V1_Male:{v1_g_m} '  )\n","\n","  if v4_g_f >= v1_g_f :\n","    s6=(f\"Video 4 has Higher Number of Female on Count compared with Benchmark video : Gender : Female count in video 4:{v4_g_f}  Female count in benchmark video:{v1_g_f} \"   )\n","    #ss6=(f'Gender : V4_Female:{v4_g_f}  V1_Female:{v1_g_f} '  )\n","  else:\n","      s6=(f\"Benchmark video has Higher Number of Female on Count compared with Video 4 : Gender : Female count in video 4:{v4_g_f}  Female count in benchmark video:{v1_g_f}\"   )\n","      #ss6=(f'Gender : V4_Female:{v4_g_f}  V1_Female:{v1_g_f} '  )\n","  \n","  if v5_g_m >= v1_g_m :\n","    s7=(f\"Video 5 has Higher Number of Male on Count compared with Benchmark video : Gender :  Male count in video 5:{v5_g_m}  Male count in benchmark video:{v1_g_m} \"   )\n","    #ss7=(f'Gender : V5_Male:{v5_g_m}  V1_Male:{v1_g_m} '  )\n","  else:\n","      s7=(f\"Benchmark video has Higher Number of Male on Count compared with Video 5 : Gender :  Male count in video 5:{v5_g_m}  Male count in benchmark video:{v1_g_m} \"   )\n","      #ss7=(f'Gender : V5_Male:{v5_g_m}  V1_Male:{v1_g_m} '  )\n","  \n","  if v5_g_f >= v1_g_f :\n","    s8=(f\"Video 5 has Higher Number of Female on Count compared with Benchmark video : Gender : Female count in video 5:{v5_g_f}  Female count in benchmark video:{v1_g_f}\"   )\n","    #ss8=(f'Gender : V5_Female:{v5_g_f}  V1_Female:{v1_g_f} '  )\n","  else:\n","      s8=(f\"Benchmark video has Higher Number of Female on Count compared with Video 5 : Gender : Female count in video 5:{v5_g_f}  Female count in benchmark video:{v1_g_f} \"   )\n","      #ss8=(f'Gender : V5_Female:{v5_g_f}  V1_Female:{v1_g_f} '  )\n","\n","  gender_msg=[s1,s2,s3,s4,s5,s6,s7,s8]  \n","  a= v1_a[:1,]\n","  b= v2_a[:1,]\n","  c= v3_a[:1,]\n","  d= v4_a[:1,]\n","  e = v5_a[:1,]\n","\n","  df1 ={'videos':['v1','v2','v3','v4','v5'], 'ages':[a,b,c,d,e]}\n","  df2 = pd.DataFrame(df1)\n","\n","  ax = df2['ages'].value_counts().plot(kind='bar',\n","                                    figsize=(8,5),\n","                                    title=\"Comparision - Ages\", rot='0')\n","  ax.set_xlabel(\"videos\")\n","  ax.set_ylabel(\"Count\")\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/finalages.png')\n","\n","  df2['ages'] = df2['ages'].astype(float)\n","  df2.ages = pd.to_numeric(df2.ages)\n","  ax = df2.plot.bar(x='videos', y='ages', rot=0)\n","  plt.savefig('/content/drive/MyDrive/Task/Visualization/videos_ages.png')\n","\n","  ax = df2.plot.bar(x='videos', y='ages', rot=0)\n","\n","\n","\n","  global ana_status\n","  ana_status=ana_status+1\n","  return\n","\n","\n","\n","def color():\n","    \n","\n","    #read excel files\n","    clr_df1 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_1.xlsx', \"Color\")\n","    clr_df2 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_2.xlsx', \"Color\")\n","    clr_df3 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_3.xlsx', \"Color\")\n","    clr_df4 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_4.xlsx', \"Color\")\n","    clr_df5 = pd.read_excel(r'/content/drive/MyDrive/Task/Folder_5.xlsx', \"Color\")\n","\n","    #CREATE PLOTS\n","    #video1\n","    ax = clr_df1['color_name'].value_counts().plot(kind='bar',\n","                                        figsize=(8,4),\n","                                        title=\"Video 1 - Diversity\", rot='0')\n","    ax.set_xlabel(\"Color\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V1_Clr.png')\n","\n","    #video2\n","    ax = clr_df2['color_name'].value_counts().plot(kind='bar',\n","                                        figsize=(12,6),\n","                                        title=\"Video 2 - Diversity\", rot='0')\n","    ax.set_xlabel(\"Color\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V2_Clr.png')\n","\n","    #video3\n","    ax = clr_df3['color_name'].value_counts().plot(kind='bar',\n","                                        figsize=(12,6),\n","                                        title=\"Video 3 - Diversity\", rot='0')\n","    ax.set_xlabel(\"Color\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V3_Clr.png')\n","\n","    #video4\n","    ax = clr_df4['color_name'].value_counts().plot(kind='bar',\n","                                        figsize=(8,5),\n","                                        title=\"Video 4 - Diversity\", rot='0')\n","    ax.set_xlabel(\"Color\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V4_Clr.png')\n","\n","    #video5\n","    ax = clr_df5['color_name'].value_counts().plot(kind='bar',\n","                                        figsize=(8,5),\n","                                        title=\"Video 5 - Diversity\", rot='0')\n","    ax.set_xlabel(\"Color\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V5_Clr.png')\n","\n","    clr1 = clr_df1['color_name'].value_counts()\n","    clr2 = clr_df2['color_name'].value_counts()\n","    clr3 = clr_df3['color_name'].value_counts()\n","    clr4 = clr_df4['color_name'].value_counts()\n","    clr5 = clr_df5['color_name'].value_counts()\n","\n","    a= clr1[:2,]\n","    b= clr2[:2,]\n","    c= clr3[:2,]\n","    d= clr4[:2,]\n","    e= clr5[:2,]\n","\n","    df1 ={'videos':['v1','v2','v3','v4','v5'], 'clr':[a,b,c,d,e]}\n","    df2 = pd.DataFrame(df1)\n","    ax = df2['clr'].value_counts().plot(kind='bar',\n","                                        figsize=(8,5),\n","                                        title=\"Video 4 - Diversity\", rot='0')\n","    ax.set_xlabel(\"videos\")\n","    ax.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V6_Clr.png')\n","    global ana_status\n","    ana_status=ana_status+1\n","    return\n","\n","\n","def emotion():\n","    global Emo_rec\n","    #read excel files\n","    em_df1 = pd.read_excel(r'/content/drive/MyDrive/Task/Emotions_Folder_1.xlsx', \"Emotions\")\n","    em_df2 = pd.read_excel(r'/content/drive/MyDrive/Task/Emotions_Folder_2.xlsx', \"Emotions\")\n","    em_df3 = pd.read_excel(r'/content/drive/MyDrive/Task/Emotions_Folder_3.xlsx', \"Emotions\")\n","    em_df4 = pd.read_excel(r'/content/drive/MyDrive/Task/Emotions_Folder_4.xlsx', \"Emotions\")\n","    em_df5 = pd.read_excel(r'/content/drive/MyDrive/Task/Emotions_Folder_5.xlsx', \"Emotions\")\n","\n","    #CREATE PLOTS\n","    em_df1 = em_df1.rename(columns = {\"Unnamed:0\" : \"level\"})\n","\n","    he1=[em_df1['Emotion Value'].iloc[0],em_df2['Emotion Value'].iloc[0],em_df3['Emotion Value'].iloc[0],em_df4['Emotion Value'].iloc[0],em_df5['Emotion Value'].iloc[0]]\n","    max_value = max(he1)\n","    index = he1.index(max_value)\n","    Emo_rec1 = em_df1['Human Emotions'].iloc[0] + \" emotion is highest in Video \" + str(index+1)\n","    \n","    he2=[em_df1['Emotion Value'].iloc[1],em_df2['Emotion Value'].iloc[1],em_df3['Emotion Value'].iloc[1],em_df4['Emotion Value'].iloc[1],em_df5['Emotion Value'].iloc[1]]\n","    max_value = max(he2)\n","    index = he2.index(max_value)\n","    Emo_rec2 = em_df1['Human Emotions'].iloc[1] + \" emotion is highest in Video \" + str(index+1)\n","\n","    he3=[em_df1['Emotion Value'].iloc[2],em_df2['Emotion Value'].iloc[2],em_df3['Emotion Value'].iloc[2],em_df4['Emotion Value'].iloc[2],em_df5['Emotion Value'].iloc[2]]\n","    max_value = max(he3)\n","    index = he3.index(max_value)\n","    Emo_rec3 = em_df1['Human Emotions'].iloc[2] + \" emotion is highest in Video \" + str(index+1)\n","\n","    he4=[em_df1['Emotion Value'].iloc[3],em_df2['Emotion Value'].iloc[3],em_df3['Emotion Value'].iloc[3],em_df4['Emotion Value'].iloc[3],em_df5['Emotion Value'].iloc[3]]\n","    max_value = max(he4)\n","    index = he4.index(max_value)\n","    Emo_rec4 = em_df1['Human Emotions'].iloc[3] + \" emotion is highest in Video \" + str(index+1)\n","\n","    he5=[em_df1['Emotion Value'].iloc[4],em_df2['Emotion Value'].iloc[4],em_df3['Emotion Value'].iloc[4],em_df4['Emotion Value'].iloc[4],em_df5['Emotion Value'].iloc[4]]\n","    max_value = max(he5)\n","    index = he5.index(max_value)\n","    Emo_rec5 = em_df1['Human Emotions'].iloc[4] + \" emotion is highest in Video \" + str(index+1)\n","\n","    he6=[em_df1['Emotion Value'].iloc[5],em_df2['Emotion Value'].iloc[5],em_df3['Emotion Value'].iloc[5],em_df4['Emotion Value'].iloc[5],em_df5['Emotion Value'].iloc[5]]\n","    max_value = max(he6)\n","    index = he6.index(max_value)\n","    Emo_rec6 = em_df1['Human Emotions'].iloc[5] + \" emotion is highest in Video \" + str(index+1)\n","\n","    he7=[em_df1['Emotion Value'].iloc[6],em_df2['Emotion Value'].iloc[6],em_df3['Emotion Value'].iloc[5],em_df4['Emotion Value'].iloc[5],em_df5['Emotion Value'].iloc[5]]\n","    max_value = max(he7)\n","    index = he7.index(max_value)\n","    Emo_rec7 = em_df1['Human Emotions'].iloc[6] + \" emotion is highest in Video \" + str(index+1)\n","\n","    Emo_rec=[Emo_rec1,Emo_rec2,Emo_rec3,Emo_rec4,Emo_rec5,Emo_rec6,Emo_rec7]\n","    print(Emo_rec)\n","    \n","    #Plot all video emotions in one plot\n","    vv1=em_df1.loc[0,['Human Emotions','Emotion Value']].tolist()\n","    vv1.insert(0,'Video 1')\n","    vv2=em_df2.loc[0,['Human Emotions','Emotion Value']].tolist()\n","    vv2.insert(0,'Video 2')\n","    vv3=em_df3.loc[0,['Human Emotions','Emotion Value']].tolist()\n","    vv3.insert(0,'Video 3')\n","    vv4=em_df4.loc[0,['Human Emotions','Emotion Value']].tolist()\n","    vv4.insert(0,'Video 4')\n","    vv5=em_df5.loc[0,['Human Emotions','Emotion Value']].tolist()\n","    vv5.insert(0,'Video 5')\n","    df = pd.DataFrame(columns = [\"Video\",\"Human Emotions\",\"Emotion Value\"])\n","    #df = pd.DataFrame(vv1, columns =[\"Video\",\"Human Emotions\",\"Emotion Value\"])\n","    df2 = df.append(pd.Series(vv1, index = [\"Video\",\"Human Emotions\",\"Emotion Value\"]), ignore_index=True)\n","    df2 = df2.append(pd.Series(vv2, index = [\"Video\",\"Human Emotions\",\"Emotion Value\"]), ignore_index=True)\n","    df2 = df2.append(pd.Series(vv3, index = [\"Video\",\"Human Emotions\",\"Emotion Value\"]), ignore_index=True)\n","    df2 = df2.append(pd.Series(vv4, index = [\"Video\",\"Human Emotions\",\"Emotion Value\"]), ignore_index=True)\n","    df2 = df2.append(pd.Series(vv5, index = [\"Video\",\"Human Emotions\",\"Emotion Value\"]), ignore_index=True)\n","\n","    x=df2[\"Video\"].tolist()\n","    y=df2[\"Emotion Value\"].tolist()\n","    z=df2[\"Human Emotions\"].tolist()\n","\n","    ex = df2.plot(x=\"Video\", y=[\"Emotion Value\"], kind=\"bar\",  color=\"C2\" , figsize=(8,4),\n","                                        title=\"Highest Emotions in All Videos\", rot='0')  \n","    j=0\n","    xlocs, xlabs = plt.xticks()\n","    for i, v in enumerate(y):\n","        plt.text(xlocs[i] - 0.20, v + 0.5, z[i])\n","        j=j+1\n","\n","    ex.set_xlabel(\"Human Emotions\")\n","    ex.set_ylabel(\"Emotion Level in Entire Video\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/All_Emotion.png')\n","\n","    #video1\n","    ex = em_df1.plot(x=\"Human Emotions\", y=[\"Emotion Value\"], kind=\"bar\",  color=\"C2\" , figsize=(8,4),\n","                                        title=\"Emotions in Video 1\", rot='0')  \n","\n","    ex.set_xlabel(\"Human Emotions\")\n","    ex.set_ylabel(\"Emotion Level in Entire Video\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V1_Emotion.png')\n","\n","    #video2\n","    ex = em_df2.plot(x=\"Human Emotions\", y=[\"Emotion Value\"], kind=\"bar\",  color=\"C2\" , figsize=(8,4),\n","                                        title=\"Emotions in Video 2\", rot='0')  \n","\n","    ex.set_xlabel(\"Human Emotions\")\n","    ex.set_ylabel(\"Emotion Level in Entire Video\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V2_Emotion.png')\n","\n","    #video3\n","    ex = em_df3.plot(x=\"Human Emotions\", y=[\"Emotion Value\"], kind=\"bar\",  color=\"C2\" , figsize=(8,4),\n","                                        title=\"Emotions in Video 3\", rot='0')  \n","\n","    ex.set_xlabel(\"Human Emotions\")\n","    ex.set_ylabel(\"Emotion Level in Entire Video\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V3_Emotion.png')\n","    \n","    #video4\n","    ex = em_df4.plot(x=\"Human Emotions\", y=[\"Emotion Value\"], kind=\"bar\",  color=\"C2\" , figsize=(8,4),\n","                                        title=\"Emotions in Video 4\", rot='0')  \n","\n","    ex.set_xlabel(\"Human Emotions\")\n","    ex.set_ylabel(\"Emotion Level in Entire Video\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V4_Emotion.png')\n","\n","    #video5\n","    ex = em_df5.plot(x=\"Human Emotions\", y=[\"Emotion Value\"], kind=\"bar\",  color=\"C2\" , figsize=(8,4),\n","                                        title=\"Emotions in Video 5\", rot='0')  \n","\n","    ex.set_xlabel(\"Human Emotions\")\n","    ex.set_ylabel(\"Emotion Level in Entire Video\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/V5_Emotion.png')\n","    \n","    global ana_status\n","    ana_status=ana_status+1\n","\n","def feature_extraction(file):\n"," features=[]\n"," (sampleRate,data) = wav.read(file)\n"," mfcc_feature = mfcc(data,sampleRate,\n","                           winlen=0.020,\n","                           appendEnergy = False)\n"," meanMatrix = mfcc_feature.mean(0)\n"," for x in meanMatrix:\n","   features.append(x)\n"," return features\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import os.path\n","\n","def feature_extraction(file):\n"," features=[]\n"," (sampleRate,data) = wav.read(file)\n"," mfcc_feature = mfcc(data,sampleRate,\n","                           winlen=0.020,\n","                           appendEnergy = False)\n"," meanMatrix = mfcc_feature.mean(0)\n"," for x in meanMatrix:\n","   features.append(x)\n"," return features\n","\n","def music():\n","    directory = \"/content/drive/MyDrive/Task/Dataset\"\n","    filelist=[]\n","    for path, subdirs, files in os.walk(directory):\n","        for file in files:\n","            if (file.endswith('.wav') or file.endswith('.WAV')):\n","                filelist.append(os.path.join(path, file))\n","    number_of_files=len(filelist)\n","    print(number_of_files)\n","\n","    datasetDirectory = \"/content/drive/MyDrive/Task/Dataset/\"\n","    os.chdir(datasetDirectory) \n","    featureSet=[]\n","    i=0\n","    for folder in os.listdir(datasetDirectory):\n","        i+=1\n","        if i > 9: # the number of genres is 9\n","            break  \n","        for files in os.listdir(datasetDirectory+folder):\n","            x=datasetDirectory+folder+\"/\"+files\n","            features=feature_extraction(x)\n","            j=0\n","            for x in features:\n","                featureSet.append(x)\n","                j=j+1\n","                if(j%13==0):\n","                    featureSet.append(i) \n","    df = pd.DataFrame(columns=['m1','m2','m3','m4','m5','m6','m7',\n","                          'm8','m9','m10','m11','m12','m13','target'])\n","    \n","    i=1\n","    n=[]\n","    for j in featureSet:\n","        n.append(j)\n","        #13 features + 1 taget\n","        if(i%14==0):\n","            df = df.append({'m1':n[0],'m2':n[1],'m3':n[2],'m4':n[3],'m5':n[4],\n","                            'm6':n[5],'m7':n[6],'m8':n[7],'m9':n[8],'m10':n[9],\n","                            'm11':n[10],'m12':n[11],'m13':n[12],'target':n[13]},\n","                            ignore_index=True)\n","            n=[]\n","        i=i+1\n","    \n","    x1=df[['m1','m2','m3','m4','m5','m6','m7','m8','m9','m10','m11','m12','m13']]\n","    Y = df[['target']]\n","    from sklearn.model_selection import train_test_split\n","    X_train, X_test, y_train, y_test = train_test_split(x1, Y,\n","                                                    test_size=0.2,\n","                                                    random_state=3)\n","\n","    \n","    results_knn = []\n","    for i in range(1,20):\n","        knn = KNeighborsClassifier(n_neighbors =i)\n","        knn.fit(X_train, y_train)\n","        results_knn.append(knn.score(X_test, y_test))\n","\n","    max_accuracy_knn = max(results_knn)\n","    best_k = 1+results_knn.index(max(results_knn))\n","    print(\"Max Accuracy is {:.3f} on test dataset with {} neighbors.\\n\".format(max_accuracy_knn, best_k))\n","\n","    plt.plot(np.arange(1,20), results_knn)\n","    plt.xlabel(\"n Neighbors\")\n","    plt.ylabel(\"Accuracy\")\n","\n","    knn = KNeighborsClassifier(n_neighbors = best_k)\n","    knn.fit(X_train, y_train)\n","\n","    \n","    vocal_files = []\n","    for dirpath, dirnames, filenames in os.walk(\"/content/drive/MyDrive/Task/audioout\"):\n","        for filename in [f for f in filenames if f.startswith(\"accompaniment\")]:\n","            vocal_files.append(os.path.join(dirpath, filename))\n","            print (os.path.join(dirpath, filename))\n","\n","    from collections import defaultdict\n","\n","    music_video_file = 1\n","    music_out = []\n","    ms_no=[]\n","    for i in range(0, len(vocal_files)):\n","        print(i)\n","        temp5 = vocal_files[i]\n","        audio_file= temp5\n","        print(audio_file)\n","        audio_feature = feature_extraction(audio_file)\n","        print(\"extracted\")\n","        results=defaultdict(int)\n","        i=1\n","        for folder in os.listdir(\"/content/drive/MyDrive/Task/Dataset/\"):\n","            results[i]=folder\n","            i+=1\n","        pred_audio=knn.predict([audio_feature])\n","        print(results[int(pred_audio)])\n","        music_out.append(results[int(pred_audio)])\n","        ms_no.append(music_video_file )\n","        music_video_file += 1\n","    print(\"\\nType of Music\", music_out)\n","    print(\"\\nMS Num: \", ms_no)\n","    \n","    return_data4 = pd.DataFrame({'ms_no':ms_no,'Music_out': music_out})\n","    excel_name = \"/content/drive/MyDrive/Task/Music_type\" + \".xlsx\"\n","    excelfile = pd.ExcelWriter(excel_name)\n","    return_data4.to_excel(excelfile, \"music output\", index = False)\n","    excelfile.save()\n","\n","    music_df1 = pd.read_excel(r'/content/drive/MyDrive/Task/Music_type.xlsx', \"music output\")\n","\n","    mx = music_df1['Music_out'].value_counts().plot(kind='bar', color = \"C4\",\n","                                        figsize=(12,5),\n","                                        title=\"Music From Videos\", rot='0', )\n","    mx.set_xlabel(\"Music Types from V1, V2, V3, V4, V5\")\n","    mx.set_ylabel(\"Count\")\n","    plt.savefig('/content/drive/MyDrive/Task/Visualization/music1.png')\n","    global ana_status\n","    ana_status=ana_status+1\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sl1HHiJOGNHJ"},"outputs":[],"source":["#!pip install flask-ngrok\n","#!pip install youtube_dl\n","#!curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list && sudo apt update && sudo apt install ngrok   \n","\n","#######################################################################################################\n","\n","#GLOBAL VARIABLES\n","#video_links=['https://www.youtube.com/watch?v=d_ry4SYTYZs', 'https://www.youtube.com/watch?v=k89SBm3E8qg', 'https://www.youtube.com/watch?v=xESS5RIgFnQ', 'https://www.youtube.com/watch?v=1rB4VsMVH8Q']\n","#keyword='oppo+ads'\n","#location='india'\n","video_links=[]\n","keyword=''\n","location=''\n","\n","status=0\n","ana_status=0\n","\n","df11 = []\n","df12 = []\n","startt=0\n","anl=0\n","obj_msg=[]\n","gender_msg=[]\n","Emo_rec=[]\n","dwnld=0\n","\n","def frame():\n","    #sleep(1)\n","    print(\"creating frames>>>>>>>>>>>>>>>\")\n","    rem_path = 'save'\n","    dir = rem_path\n","    if os.path.exists(dir):\n","        shutil.rmtree(dir)\n","        os.makedirs(dir)\n","        print(\"removed\")\n","    else:\n","        os.makedirs(dir)\n","        print(\"made\")\n","    \n","    #video_paths=['/content/drive/MyDrive/Task/video.mp4']\n","    video_paths = glob(r\"/content/drive/MyDrive/Task/*.mp4\")\n","    print(video_paths)\n","    skip_n_frames = 15\n","    save_dir = \"save\"\n","    for path in video_paths:\n","        name = path.split(\"/\")[-1].split(\".\")[0]\n","        print(name)\n","        save_path = os.path.join(save_dir, name)\n","        print(save_path)\n","        if not os.path.exists(save_path):\n","            os.makedirs(save_path)\n","        \n","        count = 0\n","        cap = cv2.VideoCapture(path)\n","\n","        while True:\n","            ret, frame = cap.read()\n","            if ret == False:\n","                cap.release()\n","                break\n","            if count % skip_n_frames == 0:\n","                cv2.imwrite(f\"{save_path}/{count}.jpg\", frame)\n","\n","            count += 1\n","\n","    print(\"Done>>>>>>>>>>>>>>>>>>frames\")\n","    global ana_status\n","    ana_status=ana_status+1\n","    \n","    return \n","\n","#######################################################################s#########################\n","\n","def task(search_keyword):\n","    sleep(1)\n","    global status\n","    status=0\n","    import urllib.request\n","    import re\n","    import os\n","    import glob\n","    import pandas as pd\n","    import youtube_dl\n","    from glob import glob\n","    \n","    target = r'/content/drive/MyDrive/Task/'\n","\n","    for x in os.listdir(target):\n","                if x.endswith('.mp4'):\n","                    print(x)\n","                    os.unlink(target + x)\n","\n","            #download benchmark videos\n","            #search_keyword = input(\"Keyword: \")\n","    video_lnk=[]\n","    URLL=\"https://www.youtube.com/results?search_query=\"+search_keyword+\"&sp=CAMSBggFEAEYAQ%253D%253D\"\n","    html =urllib.request.urlopen(URLL)\n","    video_ids = re.findall(r\"watch\\?v=(\\S{11})\", html.read().decode())\n","    video_ids = video_ids[0:4]\n","    global video_links\n","    for vid in video_ids : \n","        video_lnk.append(f\"https://www.youtube.com/watch?v=\" + vid)\n","\n","    for i in range(len(video_lnk)):\n","        url= video_lnk[i]\n","        print(url)       \n","        ydl_opts = {\n","            'nooverwrites': True,\n","            'format':'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best'\n","        }\n","        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n","            ydl.download([url])\n","            \n","        print(\"successfully\")\n","        video_links.append(url)\n","        i=i+1\n","        if i>=4:\n","            break\n","\n","    path = glob(r\"/content/drive/MyDrive/Task/*.mp4\")\n","    i=1\n","    print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>',path)\n","    for file in path:\n","        src = file\n","        dst = \"video\"+str(i)+\".mp4\"\n","        os.rename(src,dst)\n","        i+=1  \n","    status = status +1\n","    print(status)\n","    print(video_lnk)\n","    global allow_upload\n","    allow_upload=1\n","    return      \n","\n","#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>FLASK APP>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","from flask import Flask, render_template, request, jsonify\n","app = Flask(__name__,template_folder='/content/drive/MyDrive/Task/templates',static_folder='/content/drive/MyDrive/Task/Visualization')#__name__ is the wsgi application\n","\n","run_with_ngrok(app)\n","\n","@app.route('/')\n","def welcome():\n","\n","    msg='Enter your keyword -> Ex: oppo+ads, and Press submit button'\n","    return render_template('index.html',status=status,clickmsg=msg,loadd='none',anlys='none')\n","    #return render_template('index.html',clickmsg=msg)\n","\n","@app.route('/research',methods=['POST','GET'])\n","def research():\n","    global status\n","    status=0\n","    global video_links\n","    video_links=[]\n","    global ana_status\n","    ana_status=0\n","    global keyword\n","    keyword=''\n","    global location\n","    location=''\n","    global df11\n","    df11 = []\n","    global df12\n","    df12 = []\n","    global startt\n","    startt=0\n","    global anl\n","    anl=0\n","    global obj_msg, gender_msg,Emo_rec \n","    obj_msg=[]\n","    gender_msg=[]\n","    Emo_rec=[]\n","    global dwnld\n","    dwnld=0\n","\n","    msg='Enter your keyword -> Ex: oppo+ads, and Press submit button'\n","    return render_template('index.html',status=status,clickmsg=msg,loadd='none',anlys='none')\n","\n","@app.route('/submit',methods=['POST','GET'])\n","def submit():\n","    global status\n","    status=0    \n","    global startt\n","    global dwnld\n","    global keyword, location\n","    rec='recommend'\n","    if request.method=='POST':\n","        keyword=request.form['keyword']\n","        location=request.form['location']\n","        print('LOCATION>>>>>>>>>>>>>',location)\n","        # location='india'\n","        startt=1\n","        task(keyword)\n","        dwnld=1\n","        print('video_links')\n","        print(video_links)\n","        #return render_template('index.html',msg11='List of downloaded videos',data=video_links)#\n","        #return render_template('Findex.html',status=status,clickmsg=' ',loadd='Block')\n","        return render_template('index.html',status=status,loadd='none',anlys='none',msg12='Video Downloaded',data1=video_links)\n","    \n","msg12='Benchmark videos downloaded, please proceed with upload your video'\n","msg13='Soure Links'\n","msg14='Benchmark videos downloaded, please proceed with upload your video'\n","msgUpload=\"Video uploaded successfully, click on analyze\"\n","@app.route('/status_download', methods=['POST','GET'])\n","def status_download():\n","  if request.method == 'POST':\n","    global status\n","    global df11, df12\n","    print('status_download print(ana_status)')\n","    print(ana_status)\n","    count1=0\n","    video_lin=video_links\n","    count1=len(video_links)       \n","    if dwnld == 1:\n","        if status < 2:\n","            if count1 < 4:\n","                print(\"status < 2\")\n","                print(count1)\n","                if startt==0:\n","                    clickmsg='Enter your keyword -> Ex: oppo+ads, and Press submit button'\n","                    return render_template('index.html',loadd='none',anlys='none',clickmsg=clickmsg,count=count1,status=status)\n","                else:\n","                    return render_template('index.html',count=count1,status=status,loadd='Block',anlys='none')\n","            else:\n","                print(\"status < 2 else\")\n","                print(count1)\n","                return render_template('index.html',count=count1,status=status,loadd='none',anlys='none',msg13=msg13,msg14=msg14,data1=video_lin[0],data2=video_lin[1],data3=video_lin[2],data4=video_lin[3])\n","        elif status == 2:\n","            print(\"status == 2\")\n","            print(count1)\n","            \n","            if anl < 1:\n","                return render_template('index.html',status=status,loadd='none',anlys='none',msg13=msg13,msg14=msgUpload,data1=video_lin[0],data2=video_lin[1],data3=video_lin[2],data4=video_lin[3])\n","            else:\n","                return render_template('index.html',status=status,loadd='none',anlys='block',msg13=msg13,msg14=msgUpload,data1=video_lin[0],data2=video_lin[1],data3=video_lin[2],data4=video_lin[3])\n","        else:        \n","            if ana_status < 11: \n","                print(\"ana_status < 11\")\n","                print(ana_status)\n","                #return render_template('index.html',loadd='none',anlys='block',msg12='ana_status < 11',msg13=msg13,msg14=msgUpload,data1=video_lin[0],data2=video_lin[1],data3=video_lin[2],data4=video_lin[3],count=count1,status=status)\n","                return render_template('index.html',status=status,loadd='none',anlys='block',msg13=msg13,msg14='Analyze in process...',data1=video_lin[0],data2=video_lin[1],data3=video_lin[2],data4=video_lin[3])\n","            else:\n","                print(\"ana_status == 11\")\n","                print(ana_status)\n","                return render_template('index.html',ana_status=ana_status,loadd='none',anlys='none',msg13=msg13,msg14='Analyse Done...',data1=video_lin[0],data2=video_lin[1],data3=video_lin[2],data4=video_lin[3])\n","    else :\n","        if status < 2:\n","            if count1 < 4:\n","                print(\"status < 2\")\n","                print(count1)\n","                if startt==0:\n","                    clickmsg='Enter your keyword -> Ex: oppo+ads, and Press submit button'\n","                    return render_template('index.html',loadd='none',anlys='none',clickmsg=clickmsg,count=count1,status=status)\n","                else:\n","                    return render_template('index.html',count=count1,status=status,loadd='Block',anlys='none')\n","            else:\n","                print(\"status < 2 else\")\n","                print(count1)\n","                return render_template('index.html',count=count1,status=status,loadd='none',anlys='none',msg13=msg13,msg14=msg14,data1=video_lin[0],data2=video_lin[1],data3=video_lin[2],data4=video_lin[3])\n","        elif status == 2:\n","            print(\"status == 2\")\n","            print(count1)\n","            \n","            if anl < 1:\n","                return render_template('index.html',status=status,loadd='none',anlys='none',msg13=' ',msg14=msgUpload,data1='',data2='',data3='',data4='')\n","            else:\n","                return render_template('index.html',status=status,loadd='none',anlys='block',msg13=' ',msg14=msgUpload,data1='',data2='',data3='',data4='')\n","        else:        \n","            if ana_status < 11: \n","                print(\"ana_status < 11\")\n","                print(ana_status)\n","                #return render_template('index.html',loadd='none',anlys='block',msg12='ana_status < 11',msg13=msg13,msg14=msgUpload,data1='',data2='',data3='',data4='',count=count1,status=status)\n","                return render_template('index.html',status=status,loadd='none',anlys='block',msg13=' ',msg14='Analyze in process...',data1='',data2='',data3='',data4='')\n","            else:\n","                print(\"ana_status == 11\")\n","                print(ana_status)\n","                return render_template('index.html',ana_status=ana_status,loadd='none',anlys='none',msg13=' ',msg14='Analyse Done...',data1='',data2='',data3='',data4='')\n"," \n","        \n","\n","@app.route('/upload', methods=['POST','GET'])\n","def upload():\n","      if request.method == 'POST':\n","        # if ana_status==0:\n","        #     return render_template('index.html',msg='Downloading videos please wait')\n","        key = request.files['video']\n","        key.filename='video0'\n","        key.save(r'/content/drive/MyDrive/Task/'+key.filename+'.mp4')\n","        global status\n","        status = 2\n","        print('upload===',status)\n","        print(video_links)       \n","        if dwnld == 0:\n","            return render_template('index.html',status=status,loadd='none',anlys='none',loadd1='block',msg13=' ',msg14=msgUpload,data1='',data2='',data3='',data4='')\n","        else:\n","            return render_template('index.html',status=status,loadd='none',anlys='none',loadd1='block',msg13=msg13,msg14=msgUpload,data1=video_links[0],data2=video_links[1],data3=video_links[2],data4=video_links[3])\n","\n","\n","\n","@app.route('/analyze', methods=['POST','GET'])\n","def analyze():\n","  global status\n","  status = 3\n","  \n","  if request.method == 'POST':\n","    global anl\n","    global ana_status\n","    anl=1\n","    print('start frame')\n","    frame()\n","    print('Frame done')\n","    ana()\n","    print('ana() done')\n","    face()\n","    print('face done')\n","    create_audio()\n","    print('create_audio done')\n","    speech_to_txt()\n","    print('word_cloud() start')\n","    word_cloud()\n","    print('word_cloud done')\n","    global df11,df12\n","    if dwnld == 1:\n","        df11,df12=trends(location,keyword)\n","    else:\n","        ana_status=ana_status+1\n","    print(df11)\n","    print(df12)\n","    print('trends done')\n","    obj_vis()\n","    print('obj_vis done')\n","    gender()\n","    print('gender done')\n","    color()\n","    print('ana() start')\n","    emotion()\n","    print('emotion done')\n","    print(ana_status)\n","    music()\n","    return render_template('index.html',loadd='none',anlys='none',ana_status=ana_status,urls=video_links,location=location)\n","\n","\n","@app.route('/results', methods=['POST','GET'])\n","def obj():\n","    if request.method=='POST':\n","        object_path=['V1_obj.png','V2_obj.png','V3_obj.png','V4_obj.png','V5_obj.png']\n","        gender_path=['V1_Age.png','V1_gen.png','V2_age.png','V2_gen.png','V3_age.png','V3_gen.png','V4_age.png','V4_gen.png','V5_age.png','V5_gen.png']\n","        color_path=['V1_Clr.png','V2_Clr.png','V3_Clr.png','V4_Clr.png','V5_Clr.png']\n","        emotion_path=['V1_Emotion.png','V2_Emotion.png','V3_Emotion.png','V4_Emotion.png','V5_Emotion.png','All_Emotion.png']\n","        music_path=['music1.png']\n","        word_cloud=['V0.png','V1.png','V2.png','V3.png','V4.png']\n","        if dwnld == 1:\n","            return render_template(\"output.html\",location=location,table1=df11,table2=df12,Emo_rec=Emo_rec,gender_msg=gender_msg,obj_msg=obj_msg,obj_msg1=obj_msg1,obj_msg2=obj_msg2,obj_msg3=obj_msg3,obj_msg4=obj_msg4, object_path=object_path,gender_path=gender_path,color_path=color_path,emotion_path=emotion_path,music_path=music_path,word_cloud=word_cloud)\n","        else:\n","            return render_template(\"output.html\",location=location,Emo_rec=Emo_rec,gender_msg=gender_msg,obj_msg=obj_msg,obj_msg1=obj_msg1,obj_msg2=obj_msg2,obj_msg3=obj_msg3,obj_msg4=obj_msg4, object_path=object_path,gender_path=gender_path,color_path=color_path,emotion_path=emotion_path,music_path=music_path,word_cloud=word_cloud)\n","\n","\n","\n","if __name__ == '__main__' :\n","    \n","    app.run()\n"]},{"cell_type":"markdown","metadata":{"id":"osPJ4hFDzXCB"},"source":["from IPython.display import Image\n","Image('/content/drive/MyDrive/Task/Visualization/All_Emotion.png')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"master.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}